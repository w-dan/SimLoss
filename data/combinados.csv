abstract,paraphrase_abstract,Score (0-10),Not/Bad generated
"Modifications to quark and antiquark fragmentation functions due to quark-quark (antiquark) double scattering in nuclear medium are studied systematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic scattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$, twist-four contributions from quark-quark (antiquark) rescattering also exhibit the Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon bremsstrahlung induced by multiple parton scattering. Compared to quark-gluon scattering, the modification, which is dominated by $t$-channel quark-quark (antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. Such a modification is not negligible for realistic kinematics and finite medium size. The modifications to quark (antiquark) fragmentation functions from quark-antiquark annihilation processes are shown to be determined by the antiquark (quark) distribution density in the medium. The asymmetry in quark and antiquark distributions in nuclei will lead to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions.","The study examines how quark and antiquark fragmentation functions are altered in deeply inelastic scattering (DIS) off nuclear targets when quarks and antiquarks interact with each other twice in the presence of a nuclear medium. These modifications are investigated systematically up to order \cal{O}(\\alpha_{s}^2). It is found that at this order, twist-four contributions from quark-quark (antiquark) rescattering display a Landau-Pomeranchuck-Midgal (LPM) interference effect, much like gluon bremsstrahlung caused by multiple parton scattering. Although the modification is dominated by $t$-channel quark-quark (antiquark) scattering, it is only slightly smaller than the quark-gluon scattering modification, with a ratio of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. This adjustment is significant for practical kinematics and finite medium sizes. Quark (antiquark) fragmentation function modifications arising from quark-antiquark annihilation processes are seen to depend on the antiquark (quark) distribution density within the medium. Since nuclei have an asymmetric quark and antiquark distribution, quark and antiquark fragmentation functions inside a nucleus will be modified differently, which can explain the experimental observation of leading hadron suppression's flavor dependence in semi-inclusive DIS off nuclear targets. Moreover, quark-antiquark annihilation processes blend quark and gluon fragmentation functions in the vast fractional momentum area, resulting in a flavor-dependent jet quenching in heavy-ion collisions.",8,False
"A physical law is represented by the probability distribution of a measured variable. The probability density is described by measured data using an estimator whose kernel is the instrument scattering function. The experimental information and data redundancy are defined in terms of information entropy. The model cost function, comprised of data redundancy and estimation error, is minimized by the creation-annihilation process.","A physical law can be encapsulated by the probability distribution of a quantifiable variable that has been observed. The likelihood of this event is detailed by recorded data utilizing an estimator, the kernel of which is the instrument's scattering function. Information entropy serves to define both the experimental knowledge gained from the data and its degree of repetition. By minimizing the model cost function, which encompasses both data redundancy and estimation error, we can achieve the most accurate representation possible through the creation-annihilation process.",8,False
"The microwave phonon stimulated emission (SE) has been experimentally and numerically investigated in a nonautonomous microwave acoustic quantum generator, called also microwave phonon laser or phaser (see previous works arXiv:cond-mat/0303188 ; arXiv:cond-mat/0402640 ; arXiv:nlin.CG/0703050) Phenomena of branching and long-time refractority (absence of the reaction on the external pulses) for deterministic chaotic and regular processes of SE were observed in experiments with various levels of electromagnetic pumping. At the pumping level growth, the clearly depined increasing of the number of coexisting SE states has been observed both in real physical experiments and in computer simulations. This confirms the analytical estimations of the branching density in the phase space. The nature of the refractority of SE pulses is closely connected with the pointed branching and reflects the crises of strange attractors, i.e. their collisions with unstable periodic components of the higher branches of SE states in the nonautonomous microwave phonon laser.","The microwave phonon stimulated emission (SE) has been studied extensively through experiments and numerical simulations in a nonautonomous microwave acoustic quantum generator, also known as a microwave phonon laser or phaser. Previous research (arXiv:cond-mat/0303188; arXiv:cond-mat/0402640; arXiv:nlin.CG/0703050) has shown that this device can exhibit complex phenomena such as branching and long-time refractority (the absence of response to external pulses) in both deterministic chaotic and regular processes of SE.",4,False
"Redundancy of experimental data is the basic statistic from which the complexity of a natural phenomenon and the proper number of experiments needed for its exploration can be estimated. The redundancy is expressed by the entropy of information pertaining to the probability density function of experimental variables. Since the calculation of entropy is inconvenient due to integration over a range of variables, an approximate expression for redundancy is derived that includes only a sum over the set of experimental data about these variables. The approximation makes feasible an efficient estimation of the redundancy of data along with the related experimental information and information cost function. From the experimental information the complexity of the phenomenon can be simply estimated, while the proper number of experiments needed for its exploration can be determined from the minimum of the cost function. The performance of the approximate estimation of these statistics is demonstrated on two-dimensional normally distributed random data.","The amount of repetition in experimental data serves as a key indicator of the intricacy of a natural occurrence and the number of experiments required to study it adequately. This duplication is quantified using the concept of entropy, which refers to the degree of uncertainty or randomness present in the probability distribution of experimental variables. However, calculating entropy can be cumbersome due to the involvement of complex integrals across multiple variables. To overcome this challenge, researchers have devised an approximated method that focuses solely on the summation of data points concerning those variables. This simplified approach enables a more practical assessment of data redundancy, accompanied by relevant experimental details and associated costs. By examining the available information, scientists can readily estimate the complexity of the phenomenon under investigation. Conversely, the optimal number of experiments necessary for thorough exploration can be determined by identifying the point where the cost function attains its minimal value. The effectiveness of this approximated technique has been illustrated through its application to two-dimensional randomly generated data sets.",9,False
"We present an x-ray spectromicroscopic investigation of single-crystalline magnetic FeMn/Co bilayers on Cu(001), using X-ray magnetic circular (XMCD) and linear (XMLD) dichroism at the Co and Fe L3 absorption edges in combination with photoelectron emission microscopy (PEEM). Using the magnetic coupling between the ferromagnetic Co layer and the antiferromagnetic FeMn layer we are able to produce magnetic domains with two different crystallographic orientations of the magnetic easy axis within the same sample at the same time. We find a huge difference in the XMLD contrast between the two types of magnetic domains, which we discuss in terms of intrinsic magneto-crystalline anisotropy of XMLD of the Co layer. We also demonstrate that due to the high sensitivity of the method, the small number of induced ferromagnetic Fe moments at the FeMn-Co interface is sufficient to obtain magnetic contrast from XMLD in a metallic system.","In this study, we utilize x-ray spectromicroscopy to investigate the properties of single-crystalline magnetic FeMn/Co bilayers grown on Cu(001) substrates. Our approach combines x-ray magnetic circular dichroism (XMCD) and linear dichroism (XMLD) at the Co and Fe L3 absorption edges with photoelectron emission microscopy (PEEM). By leveraging the magnetic interaction between the ferromagnetic Co layer and the antiferromagnetic FeMn layer, we successfully create magnetic domains with differing crystallographic orientations of the magnetic easy axis within the same sample. Notably, we observe a significant variation in XMLD contrast between these two domain types, which we attribute to the inherent magnetocrystalline anisotropy of the Co layer. The results demonstrate the high sensitivity of our technique, as even a minimal number of induced ferromagnetic Fe moments at the FeMn-Co interface yields measurable magnetic contrast via XMLD in a metallic system.",0,False
"We characterize a natural class of modular categories of prime power Frobenius-Perron dimension as representation categories of twisted doubles of finite p-groups. We also show that a nilpotent braided fusion category C admits an analogue of the Sylow decomposition. If the simple objects of C have integral Frobenius-Perron dimensions then C is group-theoretical. As a consequence, we obtain that semisimple quasi-Hopf algebras of prime power dimension are group-theoretical. Our arguments are based on a reconstruction of twisted group doubles from Lagrangian subcategories of modular categories (this is reminiscent to the characterization of doubles of quasi-Lie bialgebras in terms of Manin pairs).","We investigate a particular type of modular category, specifically those with a prime power Frobenius-Perron dimension, and show that they can be represented as twisted doubles of finite p-groups. Additionally, we demonstrate that any nilpotent braided fusion category can be decomposed in a manner similar to the Sylow decomposition, provided its simple objects have integral Frobenius-Perron dimensions. This leads to the conclusion that certain types of quasi-Hopf algebras are inherently related to groups, a result that stems from our ability to reconstruct twisted group doubles using Lagrangian subcategories within modular categories, much like the way doubles of quasi-Lie bialgebras are characterized through Manin pairs.",5,False
"We study cosmological perturbations in two-field inflation, allowing for non-standard kinetic terms. We calculate analytically the spectra of curvature and isocurvature modes at Hubble crossing, up to first order in the slow-roll parameters. We also compute numerically the evolution of the curvature and isocurvature modes from well within the Hubble radius until the end of inflation. We show explicitly for a few examples, including the recently proposed model of `roulette' inflation, how isocurvature perturbations affect significantly the curvature perturbation between Hubble crossing and the end of inflation.","In this study, we investigate the effects of non-standard kinetic terms on cosmological perturbations during two-field inflation. Using analytical calculations, we derive the spectra of both curvature and isocurvature modes at the time of Hubble crossing, taking into account slow-roll parameters up to the first order. Additionally, we perform numerical computations to track the evolution of these modes from deep inside the Hubble radius until the end of inflation. Our results demonstrate that isocurvature perturbations can have a significant impact on the curvature perturbation over time, as illustrated by specific examples such as the roulette"" inflation model.",8,False
"We present new observational results obtained for the Galactic non-thermal radio source G328.4+0.2 to determine both if this source is a pulsar wind nebula or supernova remnant, and in either case, the physical properties of this source. Using X-ray data obtained by XMM, we confirm that the X-ray emission from this source is heavily absorbed and has a spectrum best fit by a power law model of photon index=2 with no evidence for a thermal component, the X-ray emission from G328.4+0.2 comes from a region significantly smaller than the radio emission, and that the X-ray and radio emission are significantly offset from each other. We also present the results of a new high resolution (7 arcseconds) 1.4 GHz image of G328.4+0.2 obtained using the Australia Telescope Compact Array, and a deep search for radio pulsations using the Parkes Radio Telescope. We find that the radio emission has a flat spectrum, though some areas along the eastern edge of G328.4+0.2 have a steeper radio spectral index of ~-0.3. Additionally, we obtain a luminosity limit of the central pulsar of L_{1400} < 30 mJy kpc^2, assuming a distance of 17 kpc. In light of these observational results, we test if G328.4+0.2 is a pulsar wind nebula (PWN) or a large PWN inside a supernova remnant (SNR) using a simple hydrodynamic model for the evolution of a PWN inside a SNR. As a result of this analysis, we conclude that G328.4+0.2 is a young (< 10000 years old) pulsar wind nebula formed by a low magnetic field (<10^12 G) neutron star born spinning rapidly (<10 ms) expanding into an undetected SNR formed by an energetic (>10^51 ergs), low ejecta mass (M < 5 Solar Masses) supernova explosion which occurred in a low density (n~0.03 cm^{-3}) environment.","Our study focuses on the Galactic non-thermal radio source G328.4+0.2, aiming to determine its nature as either a pulsar wind nebula or supernova remnant, and to infer its physical properties. Utilizing X-ray data from XMM, we confirmed that the source's X-ray emission is heavily absorbed and can be described by a power law model with a photon index of 2, lacking any significant thermal component. The X-ray emission originates from a region smaller than the radio emission, and the two emissions are noticeably displaced from each other.",0,False
"It has been suggested that X-ray observations of rapidly variable Seyfert galaxies may hold the key to probe the gas orbital motions in the innermost regions of accretion discs around black holes and, thus, trace flow patterns under the effect of the hole strong gravitational field. We explore this possibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783. A detiled time-resolved spectral analysis is performed down to the shortest possible time-scales (few ks) using \","The study of rapidly varying Seyfert galaxies using X-ray observations may provide valuable insights into the motion of gas in the inner regions of accretion disks surrounding black holes. By examining the XMM-Newton observations of NGC 3783, a detailed analysis of the time-resolved spectra was conducted, focusing on the shortest timescales achievable (i.e., a few thousand seconds). This allowed researchers to investigate the effects of the black hole's strong gravity on the flow patterns within the disk.",0,True
"The identification of basaltic asteroids in the asteroid Main Belt and the description of their surface mineralogy is necessary to understand the diversity in the collection of basaltic meteorites. Basaltic asteroids can be identified from their visible reflectance spectra and are classified as V-type in the usual taxonomies. In this work, we report visible spectroscopic observations of two candidate V-type asteroids, (7472) Kumakiri and (10537) 1991 RY16, located in the outer Main Belt (a > 2.85 UA). These candidate have been previously identified by Roig and Gil-Hutton (2006, Icarus 183, 411) using the Sloan Digital Sky Survey colors. The spectroscopic observations have been obtained at the Calar Alto Observatory, Spain, during observational runs in November and December 2006. The spectra of these two asteroids show the steep slope shortwards of 0.70 microns and the deep absorption feature longwards of 0.75 microns that are characteristic of V-type asteroids. However, the presence of a shallow but conspicuous absorption band around 0.65 microns opens some questions about the actual mineralogy of these two asteroids. Such band has never been observed before in basaltic asteroids with the intensity we detected it. We discuss the possibility for this shallow absorption feature to be caused by the presence of chromium on the asteroid surface. Our results indicate that, together with (1459) Magnya, asteroids (7472) Kumakiri and (10537) 1991 RY16 may be the only traces of basaltic material found up to now in the outer Main Belt.","Understanding the variety of basaltic meteorites requires identifying and analyzing the surface composition of basaltic asteroids in the Main Belt. Asteroids with basaltic surfaces can be recognized by their distinctive visible reflectance spectra, which allow them to be classified as V-type asteroids. This study focuses on two V-type candidates, (7472) Kumakiri and (10537) 1991 RY16, located in the outer Main Belt. Previous studies had identified these asteroids based on their colors, and our team acquired spectroscopic data on them using the Calar Alto Observatory in Spain. The resulting spectra exhibited the expected steep slope and deep absorption features of V-type asteroids, but they also showed an unusual shallow absorption band around 0.65 microns. This band has not been seen before in basaltic asteroids, and its origin is still uncertain. One possible explanation is the presence of chromium on the asteroid surface, which we explore in our discussion. Our findings suggest that (7472) Kumakiri and (10537) 1991 RY16, along with (1459) Magnya, might be the only known examples of basaltic material in the outer Main Belt.",8,False
"In this expository article we review recent advances in our understanding of the combinatorial and algebraic structure of perturbation theory in terms of Feynman graphs, and Dyson-Schwinger equations. Starting from Lie and Hopf algebras of Feynman graphs, perturbative renormalization is rephrased algebraically. The Hochschild cohomology of these Hopf algebras leads the way to Slavnov-Taylor identities and Dyson-Schwinger equations. We discuss recent progress in solving simple Dyson-Schwinger equations in the high energy sector using the algebraic machinery. Finally there is a short account on a relation to algebraic geometry and number theory: understanding Feynman integrals as periods of mixed (Tate) motives.","Recent developments in the field of perturbation theory have led to a deeper comprehension of its combinatorial and algebraic framework, which is illuminated by Feynman diagrams and Dyson-Schwinger equations. By employing Lie and Hopf algebras associated with Feynman diagrams, researchers have been able to recast perturbative renormalization in an algebraic light. This novel perspective paves the way for deriving Slavnov-Taylor identities and Dyson-Schwinger equations through the study of Hochschild cohomology. Notably, significant strides have been made in resolving straightforward Dyson-Schwinger equations within the high-energy domain utilizing sophisticated algebraic tools. Additionally, intriguing connections between algebraic geometry and number theory have emerged, allowing us to regard Feynman integrals as periods of hybrid (Tate) motives, thereby offering fresh insights into their nature.",7,False
"In summary, when combined with other methods, radio astrometry offers a powerful tool in the quest for exoplanet discovery and understanding, showcasing its importance in the broader context of exoplanet research.",,10,True
"The relative merits of current-spin-density- and spin-density-functional theory are investigated for solids treated within the exact-exchange-only approximation. Spin-orbit splittings and orbital magnetic moments are determined at zero external magnetic field. We find that for magnetic (Fe, Co and Ni) and non-magnetic (Si and Ge) solids, the exact-exchange current-spin-density functional approach does not significantly improve the accuracy of the corresponding spin-density functional results.","The performance of current-spin-density-functional theory and spin-density-functional theory was compared for solids under the exact-exchange-only approximation, with a focus on determining spin-orbit splittings and orbital magnetic moments in the absence of an external magnetic field. The study found that for both magnetic (iron, cobalt, and nickel) and non-magnetic (silicon and germanium) solids, using the exact-exchange current-spin-density functional approach did not substantially enhance the accuracy of the results obtained from spin-density functional theory.",7,False
"The BL Lac object 3C 66A was observed in an extensive multiwavelength monitoring campaign from July 2003 till April 2004. The spectral energy distribution (SED) was measured over the entire electromagnetic spectrum, with flux measurements from radio to X-ray frequencies and upper limits in the very high energy (VHE) gamma-ray regime. Here, we use a time-dependent leptonic jet model to reproduce the SED and optical spectral variability observed during our multiwavelength campaign. Our model simulations could successfully reproduce the observed SED and optical light curves and predict an intrinsic cutoff value for the VHE gamma-ray emission at ~ 4 GeV. The effect of the optical depth due to the intergalactic infrared background radiation (IIBR) on the peak of the high-energy component of 3C 66A was found to be negligible. Also, the presence of a broad line region (BLR) in the case of 3C 66A may play an important role in the emission of gamma-ray photons when the emission region is very close to the central engine, but further out, the production mechanism of hard X-ray and gamma-ray photons becomes rapidly dominated by synchrotron self-Compton emission. We further discuss the possibility of an observable X-ray spectral variability pattern. The simulated results do not predict observable hysteresis patterns in the optical or soft X-ray regimes for major flares on multi-day time scales.","A comprehensive observational campaign spanning several months revealed that the BL Lac object 3C 66A emits energy across the entire electromagnetic spectrum, including radio waves, X-rays, and even very high-energy gamma rays. By using a time-dependent leptonic jet model, researchers were able to accurately replicate the observed variations in the object's brightness and energy output. Their analysis showed that the innate gamma-ray emission cap of 3C 66A lies around 4 GeV, and they discovered that the impact of intergalactic infrared background radiation on the object's high-energy emission is minimal. Additionally, the study suggests that a broad line region within 3C 66A plays a crucial role in producing gamma rays when the emission source is near the center of the black hole; however, at greater distances, other mechanisms take over. Finally, the study explores whether X-ray spectral changes can be detected, although the findings indicate that significant patterns are unlikely to occur in the optical or soft X-ray ranges during large flares lasting multiple days.",5,False
"Let X be a simplicial complex on the vertex set V. The rational Leray number L(X) of X is the minimal d such that the rational reduced homology of any induced subcomplex of X vanishes in dimensions d and above. Let \\pi be a simplicial map from X to a simplex Y, such that the cardinality of the preimage of any point in |Y| is at most r. It is shown that L(\\pi(X)) \\leq r L(X)+r-1. One consequence is a topological extension of a Helly type result of Amenta.","Given a simplicial complex X on vertex set V, the rational Leray number L(X) represents the minimum dimension d for which the rational reduced homology of any induced subcomplex of X disappears in dimensions d and higher. Consider a simplicial map π from X to a simplex Y with the property that the preimage of each point in |Y| has at most r elements. Then, we have L(π(X)) ≤ rL(X) + r - 1. This result leads to a topological extension of Amenta's Helly-type theorem.",8,False
"Intriguingly, our research reveals that for models containing 100,000 stars, the evolution of the core radius until the end of the primary stage of core collapse does not depend on the specific value of the primordial binary frequency, provided it falls below 10%. This insight has implications for estimating the original binary content of globular clusters.",,10,True
"The Hamiltonian cycle problem (HCP) in digraphs D with degree bound two is solved by two mappings in this paper. The first bijection is between an incidence matrix C_{nm} of simple digraph and an incidence matrix F of balanced bipartite undirected graph G; The second mapping is from a perfect matching of G to a cycle of D. It proves that the complexity of HCP in D is polynomial, and finding a second non-isomorphism Hamiltonian cycle from a given Hamiltonian digraph with degree bound two is also polynomial. Lastly it deduces P=NP base on the results.","This paper proposes a solution to the Hamiltonian Cycle Problem (HCP) in digraphs with degree bound two using two mappings. The first mapping transforms an incidence matrix of a simple digraph into an incidence matrix of a balanced bipartite undirected graph. The second mapping takes a perfect matching of the undirected graph and converts it into a Hamiltonian cycle in the original digraph. These mappings demonstrate that the complexity of HCP in digraphs with degree bound two is polynomial, and finding a second non-isomorphic Hamiltonian cycle from a given Hamiltonian digraph with degree bound two is also polynomial. Furthermore, the results imply that P=NP.",6,False
"We consider the orbit of the bullet cluster 1E 0657-56 in both CDM and MOND using accurate mass models appropriate to each case in order to ascertain the maximum plausible collision velocity. Impact velocities consistent with the shock velocity (~ 4700km/s) occur naturally in MOND. CDM can generate collision velocities of at most ~ 3800km/s, and is only consistent with the data provided that the shock velocity has been substantially enhanced by hydrodynamical effects.","The study examines the collision velocity of the Bullet Cluster 1E 0657-56 using two different theoretical frameworks: Cold Dark Matter (CDM) and Modified Newtonian Dynamics (MOND). By employing precise mass models tailored to each scenario, we aim to determine the highest possible collision velocity. Our results show that MOND can produce impact velocities matching the observed shock velocity of approximately 4700 km/s without any issues. In contrast, CDM can only achieve a maximum collision velocity of around 3800 km/s. However, if we assume that hydrodynamic effects significantly amplify the shock velocity, CDM becomes consistent with the available data.",8,False
"We study the potential of the CNGS beam in constraining the parameter space of a model with one sterile neutrino separated from three active ones by an $\\mathcal{O}(\\eVq)$ mass-squared difference, $\\Dmq_\\Sbl$. We perform our analysis using the OPERA detector as a reference (our analysis can be upgraded including a detailed simulation of the ICARUS detector). We point out that the channel with the largest potential to constrain the sterile neutrino parameter space at the CNGS beam is $\ u_\\mu \\to \ u_\\tau$. The reason for that is twofold: first, the active-sterile mixing angle that governs this oscillation is the less constrained by present experiments; second, this is the signal for which both OPERA and ICARUS have been designed, and thus benefits from an extremely low background. In our analysis we also took into account $\ u_\\mu \\to \ u_e$ oscillations. We find that the CNGS potential to look for sterile neutrinos is limited with nominal intensity of the beam, but it is significantly enhanced with a factor 2 to 10 increase in the neutrino flux. Data from both channels allow us, in this case, to constrain further the four-neutrino model parameter space. Our results hold for any value of $\\Dmq_\\Sbl \\gtrsim 0.1 \\eVq$, \\textit{i.e.} when oscillations driven by this mass-squared difference are averaged. We have also checked that the bound on $\\theta_{13}$ that can be put at the CNGS is not affected by the possible existence of sterile neutrinos.","We investigate the possibility of utilizing the CNGS beam to restrict the parameter space of a model containing one sterile neutrino with a mass-squared difference of $\mathcal{O}(\eVq)$ separating it from three active neutrinos. Our analysis uses the OPERA detector as a reference, and we note that incorporating a thorough simulation of the ICARUS detector could enhance our findings. We discover that the $\uMu \to \uTau$ channel offers the greatest potential for limiting the sterile neutrino parameter space at the CNGS beam. This is attributed to the fact that the active-sterile mixing angle governing this transition is less restricted by current experiments and because both OPERA and ICARUS were specifically designed for this signal, resulting in an exceptionally low background. Additionally, we consider $\uMu \to \uElectron$ oscillations in our analysis. While the CNGS's ability to search for sterile neutrinos is somewhat restricted with its standard intensity, increasing the neutrino flux by a factor of 2 to 10 substantially improves this potential. By examining data from both channels, we can further confine the parameter space of the four-neutrino model. Our conclusions remain valid for any value of $\Dmq_Sbl \gtrsim 0.1 \eVq$, meaning that oscillations driven by this mass-squared difference are averaged. Furthermore, we verify that the constraint on $\theta_{13}$ achievable at the CNGS remains unaffected by the presence of sterile neutrinos.",9,False
The final state interactions (FSI) model in which soft rescattering of low mass intermediate states dominates is suggested. It explains why the strong interaction phases are large in the $B_d\\to\\pi\\pi$ channel and are considerably smaller in the $B_d\\to\ho\ho$ one. Direct CP asymmetries of $B_d\\to\\pi\\pi$ decays which are determined by FSI phases are considered as well.,"The Final State Interactions (FSI) model, where soft rescattering of low mass intermediate states plays a dominant role, is proposed. This model accounts for the large strong interaction phases observed in $B_d\to\pi\pi$ decays and their significantly smaller counterparts in $B_d\to\ho\ho$ decays. Additionally, direct CP asymmetries of $B_d\to\pi\pi$ decisions, which are influenced by FSI phases, are also taken into consideration.",10,False
"We provide a quantum analysis of a DC SQUID mechanical displacement detector within the sub-critical Josephson current regime. A segment of the SQUID loop forms the mechanical resonator and motion of the latter is transduced inductively through changes in the flux threading the loop. Expressions are derived for the detector signal response and noise, which are used to evaluate the position and force detection sensitivity. We also investigate cooling of the mechanical resonator due to back reaction noise from the detector.","We analyze the performance of a DC SQUID mechanical displacement detector in the sub-critical Josephson current regime using quantum mechanics. The SQUID loop contains a segment that acts as a mechanical resonator, and its movement is converted into changes in the flux passing through the loop. We derive equations for the detector's signal response and noise, which we use to assess its position and force detection sensitivity. Additionally, we examine how the mechanical resonator cools down due to back reaction noise from the detector.",8,False
"The density dependence of the symmetry energy in the equation of state of isospin asymmetric nuclear matter is of significant importance for studying the structure of systems as diverse as the neutron-rich nuclei and the neutron stars. A number of reactions using the dynamical and the statistical models of multifragmentation, and the experimental isoscaling observable, is studied to extract information on the density dependence of the symmetry energy. It is observed that the dynamical and the statistical model calculations give consistent results assuming the sequential decay effect in dynamical model to be small. A comparison with several other independent studies is also made to obtain important constraint on the form of the density dependence of the symmetry energy. The comparison rules out an extremely \","The density dependence of the symmetry energy in the equation of state of isospin asymmetric nuclear matter is crucial for understanding the structure of various systems, including neutron-rich nuclei and neutron stars. Researchers have employed multiple approaches, such as dynamic and statistical models of multifragmentation, along with experimental observations of isoscaling, to extract information about the density dependence of the symmetry energy. These studies have shown that the dynamic and statistical model calculations are consistent when assuming a minor sequential decay effect in the dynamic model. Additionally, comparisons with other independent investigations have provided valuable constraints on the form of the density dependence of the symmetry energy. Notably, these findings exclude the possibility of an extremely... (insert extreme value or behavior)",0,False
"Because observations of galaxies and clusters have been found inconsistent with General Relativity (GR), the focus of effort in developing a Scalar Potential Model (SPM) has been on the examination of galaxies and clusters. The SPM has been found to be consistent with cluster cellular structure, the flow of IGM from spiral galaxies to elliptical galaxies, intergalactic redshift without an expanding universe, discrete redshift, rotation curve (RC) data without dark matter, asymmetric RCs, galaxy central mass, galaxy central velocity dispersion, and the Pioneer Anomaly. In addition, the SPM suggests a model of past expansion, past contraction, and current expansion of the universe. GR corresponds to the SPM in the limit in which the effect of the Sources and Sinks approximate a flat scalar potential field such as between clusters and on the solar system scale, which is small relative to the distance to a Source.","The development of a Scalar Potential Model (SPM) has primarily focused on understanding galaxies and clusters, as observations have revealed discrepancies with General Relativity (GR). The SPM has shown promise in explaining various phenomena, including cluster cellular structures, the flow of Intergalactic Gas (IGM) from spiral to elliptical galaxies, redshift without an expanding universe, discrete redshift, rotation curves (RCs) without dark matter, asymmetrical RCs, central masses and velocities of galaxies, and the Pioneer Anomaly. Moreover, the SPM proposes a scenario where the universe underwent expansion, contraction, and is currently expanding again. It's worth noting that GR can be seen as a limiting case of the SPM when the effects of sources and sinks result in a nearly flat scalar potential field, such as those encountered between clusters or on scales similar to the solar system, which are relatively small compared to the distance to a source.",10,False
"The effect of fractal normal-phase clusters on vortex dynamics in a percolative superconductor is considered. The superconductor contains percolative superconducting cluster carrying a transport current and clusters of a normal phase, acting as pinning centers. A prototype of such a structure is YBCO film, containing clusters of columnar defects, as well as the BSCCO/Ag sheathed tape, which is of practical interest for wire fabrication. Transition of the superconductor into a resistive state corresponds to the percolation transition from a pinned vortex state to a resistive state when the vortices are free to move. The dependencies of the free vortex density on the fractal dimension of the cluster boundary as well as the resistance on the transport current are obtained. It is revealed that a mixed state of the vortex glass type is realized in the superconducting system involved. The current-voltage characteristics of superconductors containing fractal clusters are obtained and their features are studied.","The behavior of vortex dynamics in a percolative superconductor containing fractal normal-phase clusters is examined. The superconductor consists of percolative superconducting clusters that carry a transport current and clusters of a normal phase that act as pinning centers. Real-world examples of such structures include YBCO films and BSCCO/Ag sheathed tapes, which are of great interest for wire production. When the superconductor transitions into a resistive state, it undergoes a percolation transition from a pinned vortex state to a resistive state, where the vortices can move freely. The study reveals that the free vortex density and resistance depend on the fractal dimension of the cluster boundary. Additionally, a mixed state of the vortex glass type is found in the superconducting system. Finally, the current-voltage characteristics of superconductors with fractal clusters are derived and their properties are investigated.",0,True
"We construct a classical solution of an Einstein-Yang-Mills system with a fourth order term with respect to the field strength of the Yang-Mills field. The solution provides a spontaneous compactification proposed by Cremmer and Scherk; ten-dimensional space-time with a cosmological constant is compactified to the four-dimensional Minkowski space with a six-dimensional sphere S^6 on which an instanton solution exists. The radius of the sphere is not a modulus but is determined by the gauge coupling and the four-derivative coupling constants and the Newton's constant. We also construct a solution of ten-dimensional theory without a cosmological constant compactified to AdS_4 x S^6.","We have developed a classical solution for an Einstein-Yang-Mills system that includes a fourth-order term related to the Yang-Mills field strength. This solution leads to spontaneous compactification, as initially suggested by Cremmer and Scherk, where ten-dimensional spacetime shrinks down to four-dimensional Minkowski space accompanied by a six-dimensional sphere (S^6). Notably, the size of this sphere isn't arbitrary; it's determined by various physical parameters such as gauge couplings, four-derivative coupling constants, and Newton's constant. Moreover, we have also devised a solution for a ten-dimensional theory without a cosmological constant that gets compactified to AdS_4 x S^6.",7,False
"Aiming at a better understand of the physical and chemical processes in the hot molecular core stage of high-mass star formation, we observed the prototypical hot core G29.96-0.02 in the 862mu band with the Submillimeter Array (SMA) at sub-arcsecond spatial resolution. The observations resolved the hot molecular core into six submm continuum sources with the finest spatial resolution of 0.36''x0.25'' (~1800AU) achieved so far. Four of them located within 7800(AU)^2 comprise a proto-Trapezium system with estimated protostellar densities of 1.4x0^5 protostars/pc^3. The plethora of ~80 spectral lines allows us to study the molecular outflow(s), the core kinematics, the temperature structure of the region as well as chemical effects. The derived hot core temperatures are of the order 300K. We find interesting chemical spatial differentiations, e.g., C34S is deficient toward the hot core and is enhanced at the UCHII/hot core interface, which may be explained by temperature sensitive desorption from grains and following gas phase chemistry. The SiO(8-7) emission outlines likely two molecular outflows emanating from this hot core region. Emission from most other molecules peaks centrally on the hot core and is not dominated by any individual submm peak. Potential reasons for that are discussed. A few spectral lines that are associated with the main submm continuum source, show a velocity gradient perpendicular to the large-scale outflow. Since this velocity structure comprises three of the central protostellar sources, this is not a Keplerian disk. While the data are consistent with a gas core that may rotate and/or collapse, we cannot exclude the outflow(s) and/or nearby expanding UCHII region as possible alternative causes of this velocity pattern.","To gain a deeper understanding of the physical and chemical processes involved in the formation of high-mass stars, we used the Submillimeter Array (SMA) to observe the hot molecular core G29.96-0.02 in the 862μm band with unprecedented spatial resolution (0.36''x0.25'', or approximately 1800 AU). Our observations revealed six distinct submm continuum sources, four of which are concentrated within an area of 7800 AU² and form a proto-Trapezium system. This system has an estimated density of 1.4 x 10⁵ protostars/pc³. By analyzing the wealth of spectral lines (~80) emitted by these sources, we were able to investigate various aspects of the hot core, including its temperature structure, molecular outflows, and chemical composition. The temperatures we measured were around 300 K. Interestingly, we found chemical differentiation across the hot core, with C34S being depleted in the center and enriched near the boundary between the hot core and the surrounding ultracompact H II (UCHII) region. This phenomenon can be attributed to temperature-sensitive desorption of grains followed by gas-phase chemistry. The SiO(8-7) line emission suggests the presence of two molecular outflows originating from the hot core region. Most other molecules exhibit central peaking emission that is not dominated by any single submm peak. Several spectral lines associated with the primary submm continuum source display a velocity gradient perpendicular to the large-scale outflow. As this velocity pattern involves three of the central protostellar sources, it is unlikely to be caused by a Keplerian disk. Although our data are consistent with a rotating and/or collapsing gas core, we cannot rule out the possibility that the outflow(s) and/or neighboring expanding UCHII region are responsible for the observed velocity gradient.",7,False
"In this paper we investigate some entanglement properties for the Hydrogen molecule considered as a two interacting spin 1/2 (qubit) model. The entanglement related to the $H_{2}$ molecule is evaluated both using the von Neumann entropy and the Concurrence and it is compared with the corresponding quantities for the two interacting spin system. Many aspects of these functions are examinated employing in part analytical and, essentially, numerical techniques. We have compared analogous results obtained by Huang and Kais a few years ago. In this respect, some possible controversial situations are presented and discussed.","In this study, we explore various entanglement characteristics of the hydrogen molecule, modeled as two interacting spin-1/2 particles (qubits). Our analysis employs both the von Neumann entropy and concurrence measures, and compares them with those of the two-interacting spin system. Using a combination of analytical and numerical methods, we examine several features of these functions. Additionally, we compare our findings with previous work by Huang and Kais, highlighting any discrepancies and engaging in a discussion of potential disagreements.",8,False
"We perform the first three-dimensional measurement of the amplitudes of $B\\to \\psi(2S) K^*$ and $B\\to \\chi_{c1} K^*$ decays and update our previous measurement for $B\\to J/\\psi K^*$. We use a data sample collected with the BaBar detector at the PEP2 storage ring, corresponding to 232 million $B\\bar B$ pairs. The longitudinal polarization of decays involving a $J^{PC}=1^{++}$ $\\chi_{c1}$ meson is found to be larger than that with a $1^{--}$ $J/\\psi$ or $\\psi(2S)$ meson. No direct {\\it CP}-violating charge asymmetry is observed.","We have measured the three-dimensional amplitudes of $B\to \psi(2S)K^*$, $B\to \chi_{c1}K^*$, and $B\to J/\psi K^*$ decays using a dataset of 232 million $B\bar{B}$ pairs collected by the BaBar detector at the PEP2 storage ring. Our analysis reveals that the longitudinal polarization of decays containing a $1^{++}\chi_{c1}$ meson is greater than those with a $1^{--}J/\psi$ or $1^{--}\psi(2S)$ meson. Furthermore, we did not observe any direct CP-violating charge asymmetry in these decays.",5,False
"This paper has been removed by arXiv administrators because it plagiarizes gr-qc/0410004, gr-qc/0603075, and others. This paper also has excessive overlap with the following papers also written by the authors or their collaborators: gr-qc/0608111, and others.","The paper in question has been taken down by arXiv moderators due to accusations of plagiarism. Specifically, it borrowed content from gr-qc/0410004, gr-qc/0603075, and other unspecified sources. Additionally, the paper shows considerable similarity to several other works authored or co-authored by the same individuals, including gr-qc/0608111.",8,False
"We give a microscopic derivation of the Clausius-Mossotti relations for a homogeneous and isotropic magneto-dielectric medium consisting of radiatively broadened atomic oscillators. To this end the diagram series of electromagnetic propagators is calculated exactly for an infinite bi-cubic lattice of dielectric and magnetic dipoles for a lattice constant small compared to the resonance wavelength $\\lambda$. Modifications of transition frequencies and linewidth of the elementary oscillators are taken into account in a selfconsistent way by a proper incorporation of the singular self-interaction terms. We show that in radiatively broadened media sufficiently close to the free-space resonance the real part of the index of refraction approaches the value -2 in the limit of $\ho \\lambda^3 \\gg 1$, where $\ho$ is the number density of scatterers. Since at the same time the imaginary part vanishes as $1/\ho$ local field effects can have important consequences for realizing low-loss negative index materials.","We provide a detailed explanation of how the Clausius-Mossotti relations can be applied to a homogenous and isotropic magneto-dielectric medium made up of radiatively broadened atomic oscillators. Our approach involves calculating the diagram series of electromagnetic propagators precisely for an infinitely large bi-cubic lattice of dielectric and magnetic dipoles, with a lattice constant that is much smaller than the resonant wavelength. In our calculation, we take into account modifications to the transition frequencies and line widths of the individual oscillators in a consistent manner by including the appropriate singular self-interaction terms. Notably, we find that when the medium is sufficiently close to the free-space resonance, the real part of the refractive index tends towards -2 as the number density of scatterers increases, while the imaginary part decreases proportionally to 1/number density of scatterers. Consequently, local field effects may play a significant role in creating low-loss materials with a negative refractive index.",10,False
"We consider the curvature of a family of warped products of two pseduo-Riemannian manifolds $(B,g_B)$ and $(F,g_F)$ furnished with metrics of the form $c^{2}g_B \\oplus w^2 g_F$ and, in particular, of the type $w^{2 \\mu}g_B \\oplus w^2 g_F$, where $c, w \\colon B \\to (0,\\infty)$ are smooth functions and $\\mu$ is a real parameter. We obtain suitable expressions for the Ricci tensor and scalar curvature of such products that allow us to establish results about the existence of Einstein or constant scalar curvature structures in these categories. If $(B,g_B)$ is Riemannian, the latter question involves nonlinear elliptic partial differential equations with concave-convex nonlinearities and singular partial differential equations of the Lichnerowicz-York type among others.","We investigate the curvature properties of a family of warped product manifolds formed by combining two pseudo-Riemannian manifolds, $(B,g_B)$ and $(F,g_F)$, with metrics that take the form $c^2g_B \oplus w^2g_F$. Specifically, we focus on the case where the metric has the form $w^{2\mu}g_B \oplus w^2g_F$, where $c, w: B \to (0,\infty)$ are smooth functions and $\mu$ is a real parameter. By deriving appropriate expressions for the Ricci tensor and scalar curvature, we aim to determine whether these warped products admit Einstein or constant scalar curvature structures. When $(B,g_B)$ is Riemannian, the problem reduces to solving nonlinear elliptic partial differential equations with concave-convex nonlinearities and singular partial differential equations of the Lichnerowicz-York type.",9,False
"In the reaction e+e- -> WW -> (q_1 qbar_2)(q_3 qbar_4) the usual hadronization models treat the colour singlets q_1 qbar_2 and q_3 qbar_4 coming from two W bosons independently. However, since the final state partons may coexist in space and time, cross-talk between the two evolving hadronic systems may be possible during fragmentation through soft gluon exchange. This effect is known as Colour Reconnection. In this article the results of the investigation of Colour Reconnection effects in fully hadronic decays of W pairs in DELPHI at LEP are presented. Two complementary analyses were performed, studying the particle flow between jets and W mass estimators, with negligible correlation between them, and the results were combined and compared to models. In the framework of the SK-I model, the value for its kappa parameter most compatible with the data was found to be: kappa_{SK-I} = 2.2^{+2.5}_{-1.3} corresponding to the probability of reconnection P_{reco} to be in the range 0.31 < P_{reco} < 0.68 at 68% confidence level with its best value at 0.52.","The study investigated the phenomenon of Color Reconnection in fully hadronic decays of W pairs at LEP using the DELPHI detector. Two independent analyses were conducted, one focusing on particle flow between jets and the other utilizing W mass estimators. The results showed that there was a non-negligible probability of cross-talk between the two hadronic systems produced by the decaying W bosons, which is known as Color Reconnection. The analysis yielded an estimate of the kappa parameter in the SK-I model, which characterizes the strength of Color Reconnection, with a best fit value of 2.2±1.3, corresponding to a probability of reconnection between 0.31 and 0.68 at 68% confidence level, with a best estimate of 0.52.",9,False
The ``atom diode'' is a laser device that lets the ground state atom pass in one direction but not in the opposite direction. We examine three-dimensional effects of that device for arbitrary atomic incidence angles on flat laser sheets and set breakdown limiting angles and velocities. It is found that a correct diodic behavior independent of the incident angle can be obtained with blue detuned lasers.,"The atom diode"" is a type of laser technology that allows atoms to pass through in only one direction, while blocking them in the opposite direction. In a recent study, researchers explored how this device performs when used with flat laser sheets and different incident angles. They discovered that by using blue-detuned lasers, they could achieve consistent diodic behavior regardless of the angle at which the atoms were approaching. This finding has important implications for controlling the flow of atoms in various applications.",8,False
"We prove an Alexander type theorem for the spectral unit ball $\\Omega_n$ showing that there are no non-trivial proper holomorphic mappings in $\\Omega_n$, $n\\geq 2$.","We demonstrate a theorem comparable to Alexander's, which states that for the spectral unit ball $\Omega_n$, there do not exist any non-trivial, proper holomorphic mappings when $n \geq 2$.",6,False
"We propose and analyze a new method to produce single and entangled photons which does not require cavities. It relies on the collective enhancement of light emission as a consequence of the presence of entanglement in atomic ensembles. Light emission is triggered by a laser pulse, and therefore our scheme is deterministic. Furthermore, it allows one to produce a variety of photonic entangled states by first preparing certain atomic states using simple sequences of quantum gates. We analyze the feasibility of our scheme, and particularize it to: ions in linear traps, atoms in optical lattices, and in cells at room temperature.","We suggest a novel approach for generating single and entangled photons without the need for cavities. This method leverages the collective enhancement of light emission that arises from entanglement in atomic ensembles. A laser pulse triggers the light emission, making the process deterministic. Additionally, our scheme enables the creation of various photonic entangled states by initially preparing specific atomic states using straightforward sequences of quantum gates. We assess the viability of our proposal and adapt it to different systems, including ions in linear traps, atoms in optical lattices, and atoms in cells at room temperature.",9,False
"Future detection/non-detection of tensor modes from inflation in CMB observations presents a unique way to test certain features of string theory. Current limit on the ratio of tensor to scalar perturbations, r=T/S, is r < 0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all known string theory inflation models predict tensor modes well below the level of detection. Therefore a possible experimental discovery of tensor modes may present a challenge to string cosmology. The strongest bound on r in string inflation follows from the observation that in most of the models based on the KKLT construction, the value of the Hubble constant H during inflation must be smaller than the gravitino mass. For the gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an extremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r > 10^{-3} would imply that the gravitinos in this class of models are superheavy, m_{3/2} > 10^{13} GeV. This would have important implications for particle phenomenology based on string theory.","Future observations of the cosmic microwave background (CMB) could provide a unique opportunity to test specific aspects of string theory by detecting or not detecting tensor modes from inflation. Currently, the ratio of tensor to scalar perturbations, represented by r, is limited to less than 0.3, but future discoveries may be made at levels between 10^-2 and 10^-3. Interestingly, all known string theory inflation models predict undetectable tensor modes, so a successful detection could pose a challenge to string cosmology. In fact, the strongest constraint on r comes from the requirement that the Hubble constant during inflation, H, must be lower than the gravitino mass, m_{3/2}, which typically results in an incredibly strict bound of r < 10^-24. However, if tensor perturbations with r greater than 10^-3 were discovered, it would suggest that the gravitinos in these models are unusually heavy, exceeding 10^13 GeV, which would significantly impact particle phenomenology based on string theory.",7,False
"We show that recent stock market fluctuations are characterized by the cumulative distributions whose tails on short, minute time scales exhibit power scaling with the scaling index alpha > 3 and this index tends to increase quickly with decreasing sampling frequency. Our study is based on high-frequency recordings of the S&P500, DAX and WIG20 indices over the interval May 2004 - May 2006. Our findings suggest that dynamics of the contemporary market may differ from the one observed in the past. This effect indicates a constantly increasing efficiency of world markets.","Recent fluctuations in the stock market have been found to follow a power scaling law with an exponent greater than 3, indicating that the distribution of price changes becomes heavier-tailed at shorter time scales. This phenomenon has been observed across different indices, including the S&P500, DAX, and WIG20, during the period spanning May 2004 to May 2006. The scaling index (alpha) increases rapidly as the sampling frequency decreases, suggesting that the market's efficiency is improving over time. These findings imply that the current market dynamics may deviate from those seen in the past, pointing towards more efficient global markets.",6,False
"The notion of topological free entropy dimension of $n-$tuples of elements in a unital C$^*$ algebra was introduced by Voiculescu. In the paper, we compute topological free entropy dimension of one self-adjoint element and topological orbit dimension of one self-adjoint element in a unital C$^*$ algebra. Moreover, we calculate the values of topological free entropy dimensions of families of generators of some unital C$^*$ algebras (for example: irrational rotation C$^*$ algebras or minimal tensor product of two reduced C$^*$ algebras of free groups).","The concept of topological free entropy dimension for $n$-tuples of elements in a unital C$^*$ algebra was first proposed by Voiculescu. In this study, we determine the topological free entropy dimension of a single self-adjoint element as well as the topological orbit dimension of another self-adjoint element in a unital C$^*$ algebra. Additionally, we evaluate the topological free entropy dimensions of certain generator families in various unital C$^*$ algebras, such as those of irrational rotation C$^*$ algebras or the minimal tensor product of two reduced C$^*$ algebras of free groups.",6,False
"Any color singlet or octet ccbar pair is created at short distances and then expands to a full size of J/psi. Such a dynamical evolution process is included here in calculations for the J/psi number distribution as a function of transverse momentum and rapidity in central Au-Au collisions at both RHIC and LHC energies. The ccbar pairs are produced in the initial collision and in the partonic system during the prethermal and thermal stages through the partonic channels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they dissociate in the latter two stages. Dissociation of ccbar in the medium occurs via two reactions: (a) color singlet ccbar plus a gluon turns to color octet ccbar, (b) color octet ccbar plus a gluon persists as color octet. There are modest yields of ccbar in the prethermal stage at RHIC energy and through the reactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average momentum in the prethermal stage at both collider energies and in the thermal stage at LHC energy. Production from the partonic system competes with the suppression of the initial yield in the deconfined medium. Consequently, a bulge within -1.5<y<1.5 has been found for the J/psi number distribution and the ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon collisions. This bulge is caused by the partonic system and is thus an indicator of a deconfined partonic medium. Based on this result we suggest the rapidity region worth measuring in future experiments at RHIC and LHC to be -3<y<3.","The formation of J/psi mesons is studied in central Au-Au collisions at Relativistic Heavy Ion Collider (RHIC) and Large Hadron Collider (LHC) energies. The analysis includes the dynamic evolution of color singlet and octet ccbar pairs, which are produced in the early stages of the collision and expand to their full size. The production mechanism involves partonic channels, such as ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, followed by dissociation reactions in the medium. The study reveals that there are moderate yields of ccbar in the prethermal stage at RHIC energy and through the mentioned partonic channels at LHC energy, competing with the suppression of the initial yield in the deconfined medium. As a result, a distinct feature in the J/psi number distribution, referred to as a bulge,"" appears within the range of -1.5<y<1.5. This phenomenon is attributed to the partonic system and serves as evidence for a deconfined partonic medium. To further investigate this phenomenon, it is suggested that future experiments at RHIC and LHC should focus on the rapidity region -3<y<3.",8,False
"The ghost and gluon propagator and the ghost-gluon and three-gluon vertex of two-dimensional SU(2) Yang-Mills theory in (minimal) Landau gauge are studied using lattice gauge theory. It is found that the results are qualitatively similar to the ones in three and four dimensions. The propagators and the Faddeev-Popov operator behave as expected from the Gribov-Zwanziger scenario. In addition, finite volume effects affecting these Green's functions are investigated systematically. The critical infrared exponents of the propagators, as proposed in calculations using stochastic quantization and Dyson-Schwinger equations, are confirmed quantitatively. For this purpose lattices of volume up to (42.7 fm)^2 have been used.","Two-dimensional SU(2) Yang-Mills theory in minimal Landau gauge was investigated using lattice gauge theory, focusing on the ghost and gluon propagator and the ghost-gluon and three-gluon vertex. Results showed similarities with those in three and four dimensions, consistent with the Gribov-Zwanziger scenario. Finite volume effects were also examined, and the critical infrared exponents of the propagators, as predicted by stochastic quantization and Dyson-Schwinger equations, were confirmed through the use of lattices up to (42.7 fm)^2 in size.",8,False
"We present an original statistical method to measure the visibility of interferences in an electronic Mach-Zehnder interferometer in the presence of low frequency fluctuations. The visibility presents a single side lobe structure shown to result from a gaussian phase averaging whose variance is quadratic with the bias. To reinforce our approach and validate our statistical method, the same experiment is also realized with a stable sample. It exhibits the same visibility behavior as the fluctuating one, indicating the intrinsic character of finite bias phase averaging. In both samples, the dilution of the impinging current reduces the variance of the gaussian distribution.","We have developed a novel statistical technique for measuring the visibility of interference in an electronic Mach-Zehnder interferometer when it is affected by low-frequency fluctuations. Our method reveals a single side lobe pattern that arises from Gaussian phase averaging, which has a variance that increases quadratically with the bias. To verify the accuracy of our approach and demonstrate its robustness, we replicated the experiment using a stable sample, which displayed identical visibility characteristics as the fluctuating sample, confirming the inherent nature of finite bias phase averaging. Notably, reducing the current used to excite the interferometer resulted in a decrease in the variance of the Gaussian distribution in both samples.",9,False
"Diamond-Like Carbon (DLC) films have been shown to demonstrate various tribological behaviors: in ultra-high vacuum (UHV), with either friction coefficients as low as 0.01 or less and very mild wear, or very high friction coefficients (>0.4) and drastic wear. These behaviors depend notably on gaseous environment, hydrogen content of the film [1], and on its viscoplastic properties [2,3]. A relation between superlow friction in UHV and viscoplasticity has indeed been established for a-C:H films and confirmed for a fluorinated sample (a-C:F:H). In this study, nanoindentation and nanoscratch tests were conducted in ambient air, using a nanoindentation apparatus, in order to evaluate tribological behaviors, as well as mechanical and viscoplastic properties of different amorphous carbon films.","Diamond-like carbon (DLC) films have exhibited diverse tribological behavior, including extremely low friction coefficients (0.01 or lower) and minimal wear in ultra-high vacuum environments, as well as high friction coefficients (above 0.4) and significant wear. The tribological behavior of DLC films is influenced by factors such as the gaseous environment, hydrogen content, and viscoplastic properties. Researchers have found a correlation between exceptionally low friction in ultra-high vacuum conditions and viscoplasticity in amorphous carbon films, which has been supported by experiments involving nanoindentation and nanoscratch testing performed in ambient air using a specialized apparatus. This study aimed to assess the tribological behaviors, mechanical properties, and viscoplastic characteristics of various amorphous carbon films.",3,False
"This paper develops a contention-based opportunistic feedback technique towards relay selection in a dense wireless network. This technique enables the forwarding of additional parity information from the selected relay to the destination. For a given network, the effects of varying key parameters such as the feedback probability are presented and discussed. A primary advantage of the proposed technique is that relay selection can be performed in a distributed way. Simulation results find its performance to closely match that of centralized schemes that utilize GPS information, unlike the proposed method. The proposed relay selection method is also found to achieve throughput gains over a point-to-point transmission strategy.","This study proposes a decentralized approach to relay selection in crowded wireless networks based on contention and chance. The chosen relay broadcasts extra parity data to the final destination, improving error correction. By examining how different factors like feedback likelihood affect the system, we demonstrate the efficacy of this method. Unlike prior methods that need global positioning systems, our solution allows for local decision-making among nodes. Our simulations show that it performs almost as well as centralized techniques and provides significant throughput benefits compared to direct communication between two devices.",7,False
"On the basis of the Fermi liquid theory, the Kadowaki-Woods ratio $A/\\gamma^2$ is evaluated by using a first principle band calculation for typical itinerant $d$ and $f$ electron systems. It is found as observed that the ratio for the $d$ electron systems is significantly smaller than the normal $f$ systems, even without considering their relatively weak correlation. The difference in the ratio value comes from different characters of the Fermi surfaces. By comparing Pd and USn$_3$ as typical cases, we discuss the importance of the Fermi surface dependence of the quasiparticle transport relaxation.","The Kadowaki-Woods ratio $A/\gamma^2$ is calculated using first-principles band calculations for both $d$ and $f$ electron systems, based on the Fermi liquid theory. The results show that the ratio for $d$ electron systems is much lower than for normal $f$ systems, despite the latter's stronger correlations. This discrepancy arises from differences in the nature of the Fermi surfaces. To illustrate this point, the authors compare the behavior of Pd and USn$_3$, two representative materials with distinct Fermi surfaces. They demonstrate that the Fermi surface plays a crucial role in determining the quasiparticle transport relaxation rate.",10,False
"An LRS Bianchi type-V cosmological models representing a viscous fluid distribution with a time dependent cosmological term $\\Lambda$ is investigated. To get a determinate solution, the viscosity coefficient of bulk viscous fluid is assumed to be a power function of mass density. It turns out that the cosmological term $\\Lambda(t)$ is a decreasing function of time, which is consistent with recent observations of type Ia supernovae. Various physical and kinematic features of these models have also been explored.","A study on Bianchi type-V cosmological models, which describe the distribution of a viscous fluid, has been conducted. The investigation assumes that the viscosity coefficient of the bulk viscous fluid varies with mass density in a power-law manner. This leads to a determinate solution for the model. Notably, the cosmological term, represented by $\Lambda(t)$, is found to decrease over time, aligning with observations of type Ia supernovae. Furthermore, various aspects of the model's physics and dynamics have been examined.",8,False
"Influence of hole shape on extraordinary optical transmission was investigated using hole arrays consisting of rectangular holes with different aspect ratio. It was found that the transmission could be tuned continuously by rotating the hole array. Further more, a phase was generated in this process, and linear polarization states could be changed to elliptical polarization states. This phase was correlated with the aspect ratio of the holes. An intuitional model was presented to explain these results.","The study examined how the shape of holes affects the unusual transmission of light through a material. Researchers used arrays of rectangular holes with varying aspect ratios to investigate this phenomenon. They discovered that the transmission could be adjusted continuously by rotating the hole array, and that this process also generated a phase shift. Additionally, the polarization state of the transmitted light could be altered from linear to elliptical. The researchers found a correlation between the phase shift and the aspect ratio of the holes. To explain their findings, they proposed an intuitive model.",9,False
"We demonstrate that radiative transitions with \\Delta l = - 1 are strongly dominating for all values of n and l, except small region where l << n.","We show that radiation transitions with a change in angular momentum of -1 are significantly more dominant than other transitions for most values of n and l, except in a small range of l where it is much less than n.",6,False
"We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to recover robust star formation and metallicity histories from galactic spectra. VESPA uses the full spectral range to construct a galaxy history from synthetic models. We investigate the use of an adaptative parametrization grid to recover reliable star formation histories on a galaxy-by-galaxy basis. Our goal is robustness as opposed to high resolution histories, and the method is designed to return high time resolution only where the data demand it. In this paper we detail the method and we present our findings when we apply VESPA to synthetic and real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the number of parameters that can be recovered from a spectrum depends strongly on the signal-to-noise, wavelength coverage and presence or absence of a young population. For a typical SDSS sample of galaxies, we can normally recover between 2 to 5 stellar populations. We find very good agreement between VESPA and our previous analysis of the SDSS sample with MOPED.","Introducing VESPA - a novel approach to extracting durable star formation and metal abundance histories from galaxy spectra. By harnessing the entire spectral range, VESPA utilizes synthetic models to reconstruct each galaxy's unique past. An adaptive parameterization grid is employed to ensure dependable star formation accounts on a case-by-case basis, prioritizing robustness over extreme precision. When applied to simulated and actual SDSS spectroscopic data, VESPA demonstrates its ability to retrieve multiple stellar populations, with recovery rates ranging from 2 to 5 for a standard SDSS sample. Notably, the number of retrievable parameters is strongly influenced by signal-to-noise, wavelength coverage, and the presence of youthful stars. The results show strong correspondence between VESPA and earlier analyses using MOPED, solidifying its effectiveness in accurately capturing galaxy evolution.",4,False
"A polynomial skew product of C^2 is a map of the form f(z,w) = (p(z), q(z,w)), where p and q are polynomials, such that f is regular of degree d >= 2. For polynomial maps of C, hyperbolicity is equivalent to the condition that the closure of the postcritical set is disjoint from the Julia set; further, critical points either iterate to an attracting cycle or infinity. For polynomial skew products, Jonsson (Math. Ann., 1999) established that f is Axiom A if and only if the closure of the postcritical set is disjoint from the right analog of the Julia set. Here we present the analogous conclusion: critical orbits either escape to infinity or accumulate on an attracting set. In addition, we construct new examples of Axiom A maps demonstrating various postcritical behaviors.","A polynomial skew product of $\mathbb{C}^2$ is a map of the form $f(z,w) = (p(z),q(z,w))$, where $p$ and $q$ are polynomials, and $f$ has degree at least $2$. We say that $f$ is hyperbolic if its postcritical set is closed and does not intersect the Julia set. Moreover, critical points either converge to an attracting cycle or tend to infinity. Jonsson showed that for polynomial skew products, $f$ satisfies Axiom A if and only if the postcritical set's closure does not meet the right Julia set counterpart. We prove a similar result: critical orbits either escape to infinity or approach an attracting set. Furthermore, we provide novel examples of Axiom A maps exhibiting diverse postcritical behaviors.",8,False
"We study fragmentation trees of Gibbs type. In the binary case, we identify the most general Gibbs-type fragmentation tree with Aldous' beta-splitting model, which has an extended parameter range $\\beta>-2$ with respect to the ${\m beta}(\\beta+1,\\beta+1)$ probability distributions on which it is based. In the multifurcating case, we show that Gibbs fragmentation trees are associated with the two-parameter Poisson--Dirichlet models for exchangeable random partitions of $\\mathbb {N}$, with an extended parameter range $0\\le\\alpha\\le1$, $\\theta\\ge-2\\alpha$ and $\\alpha<0$, $\\theta =-m\\alpha$, $m\\in \\mathbb {N}$.","We investigate fragmentation trees of the Gibbs variety, specifically in the binary and multifurcating cases. In the former, we have identified the most general Gibbs-type fragmentation tree, which is connected to Aldous' beta-splitting model and boasts an expanded parameter range of $\beta > -2$. This is noteworthy because the model is founded on the probability distributions $\beta(\beta + 1, \beta + 1)$. Moving on to the latter, we have discovered a connection between Gibbs fragmentation trees and two-parameter Poisson--Dirichlet models for exchangeable random partitions of $\mathbb{N}$. The parameters involved are $0 \leq \alpha \leq 1$, $\theta \geq -2\alpha$, and $\alpha < 0$, $\theta = -m\alpha$, $m \in \mathbb{N}$.",3,False
"We study the question of whether a composite structure of elementary particles, with a length scale $1/\\Lambda$, can leave observable effects of non-locality and causality violation at higher energies (but $\\lesssim \\Lambda$). We formulate a model-independent approach based on Bogoliubov-Shirkov formulation of causality. We analyze the relation between the fundamental theory (of finer constituents) and the derived theory (of composite particles). We assume that the fundamental theory is causal and formulate a condition which must be fulfilled for the derived theory to be causal. We analyze the condition and exhibit possibilities which fulfil and which violate the condition. We make comments on how causality violating amplitudes can arise.","The study examines whether a complex arrangement of basic particles with a size scale of $1/\Lambda$ can produce detectable signs of non-locality and causality infringement at greater energies (but less than or equal to $\Lambda$). A model-independent strategy founded on the Bogoliubov-Shirkov definition of causality is used as the basis for the investigation. The research looks at how the underlying hypothesis (of elemental building blocks) and the resulting theory (of aggregate particles) relate to one another. It is assumed that the foundational theory is causal, and a criterion is developed that must be met for the derived theory to also be causal. The requirement is investigated, along with examples that satisfy it and instances where it is violated. Additionally, the origins of causality-violating amplitudes are briefly discussed.",8,False
We relate a generic character sheaf on a disconnected reductive group with a character of a representation of the rational points of the group over a finite field extending a result known in the connected case.,"We establish a connection between a generic character sheaf on a disconnected reductive group and a character of a representation of the group's rational points over a finite field, building upon a previously known result for the connected case.",10,False
"Using probabilistic approach, the transient dynamics of sparsely connected Hopfield neural networks is studied for arbitrary degree distributions. A recursive scheme is developed to determine the time evolution of overlap parameters. As illustrative examples, the explicit calculations of dynamics for networks with binomial, power-law, and uniform degree distribution are performed. The results are good agreement with the extensive numerical simulations. It indicates that with the same average degree, there is a gradual improvement of network performance with increasing sharpness of its degree distribution, and the most efficient degree distribution for global storage of patterns is the delta function.","In studying the temporary behavior of sparsely linked Hopfield neural networks, researchers have adopted a statistical method that allows them to examine how well these networks can recall information from memory. They devised a systematic way to calculate how much each piece of data in the network overlaps with others at different times. To demonstrate their technique, they worked out the details of how it would play out in networks where each node connects to a few other nodes (following what's called a binomial distribution), networks where some nodes have many more connections than others (a power-law distribution), and networks where all nodes have roughly the same number of connections (a uniform distribution). When compared to computer simulations, their predictions held up well. Their findings suggest that when the number of connections per node stays the same, the quality of the network's recall abilities improves gradually as the distribution of node degrees becomes narrower, peaking at a delta function"" distribution.",10,False
"Environmental dielectric screening effects on exciton transition energies in single-walled carbon nanotubes (SWNTs) have been studied quantitatively in the range of dielectric constants from 1.0 to 37 by immersing SWNTs bridged over trenches in various organic solvents by means of photoluminescence and the excitation spectroscopies. With increasing environmental dielectric constant ($\\epsilon_{\m env}$), both $E_{11}$ and $E_{22}$ exhibited a redshift by several tens meV and a tendency to saturate at a $\\epsilon_{\m env} \\sim 5$ without an indication of significant ($n$,$m$) dependence. The redshifts can be explained by dielectric screening of the repulsive electron-electron interaction. The $\\epsilon_{\m env}$ dependence of $E_{11}$ and $E_{22}$ can be expressed by a simple empirical equation with a power law in $\\epsilon_{\m env}$, $E_{\m ii} = E_{\m ii}^{\\infty} + A\\epsilon_{\m env}^{-\\alpha}$. We also immersed a sample in sodium-dodecyl-sulfate (SDS) solution to investigate the effects of wrapping SWNTs with surfactant. The resultant $E_{11}$ and $E_{22}$, which agree well with Weisman's data [Nano Lett. {\\bf 3}, 1235 (2003)], are close to those of $\\epsilon_{\m env}$ of 2. However, in addition to the shift due to dielectric screening, another shift was observed so that the ($2n+m$)-family patterns spread more widely, similar to that of the uniaxial-stress-induced shift.","The study examined how the environment affects the energy levels of excited electrons in single-walled carbon nanotubes (SWNTs). Researchers used different organic solvents to change the surrounding dielectric constant and measured the resulting changes in light emission and absorption spectra. They found that as the dielectric constant increased, the energy of certain electronic transitions redshifted by tens of meV and leveled off at around $\epsilon_{\text{env}} \sim 5$. This redshift is attributed to the dielectric screening of electron-electron interactions. By fitting the data to a simple empirical equation, they found that the energy shifts follow a power-law relationship with the dielectric constant. Additionally, the researchers wrapped SWNTs in a surfactant and observed additional shifts in the electronic transitions, similar to those caused by uniaxial stress.",3,False
"The cosmological redshift phenomenon can be described by the dark matter field fluid model, the results deduced from this model agree very well with the observations. The observed cosmological redshift of light depends on both the speed of the emitter and the distance between the emitter and the observer. If the emitter moves away from us, a redshift is observed. If the emitter moves towards us, whether a redshift, a blueshift or no shift is observed will depend on the speed vs. the distance. If the speed is in the range of c(exp[-beta*D]-1) < v < 0, a redshift is observed; if the speed equals c(exp[-beta*D]-1), no shift is observed; if the speed v less than c(exp[-beta*D]-1), a blueshift is observed. A redshift will be always observed in all directions for any celestial objects as long as their distance from us is large enough. Therefore, many more redshifts than blueshifts should be observed for galaxies and supernovae, etc in the sky. This conclusion agrees with current observations. The estimated value of the redshift constant beta of the dark matter field fluid is in the range of 10^(-3) ~ 10^(-5)/Mpc. A large redshift value from a distant celestial object may not necessarily indicate that it has a large receding speed. Based on the redshift effect of dark matter field fluid, it is concluded that at least in time average all photons have the same geometry (size and shape) in all inertial reference frames and do not have length contraction effect.","The behavior of the cosmological redshift can be explained by the dark matter field fluid model, which shows a strong correlation between the predicted results and actual observations. The redshift of light is influenced by both the velocity of the source and the distance between the source and the observer. When the source moves away from the observer, a redshift occurs, while a blueshift or no shift is seen when the source approaches the observer, depending on the speed and distance. In particular, a redshift is observed when the speed falls within the range of c(exp [-β \* D] - 1) < v < 0, whereas a blueshift appears when the speed is lower than c(exp [-β \* D] - 1). As the distance to celestial objects increases, redshifts are consistently detected in all directions, which aligns with current observational data. Moreover, the abundance of redshifts exceeds blueshifts in galaxies and supernovae. The estimated value of the redshift constant β lies between 10^-3 and 10^-5/Mpc. It's important to note that a high redshift value does not necessarily imply a high recession speed. According to the redshift effect of the dark matter field fluid, photons maintain a consistent geometry across all inertial reference frames, without experiencing length contraction.",9,False
"The notion of representative statistical ensembles, correctly representing statistical systems, is strictly formulated. This notion allows for a proper description of statistical systems, avoiding inconsistencies in theory. As an illustration, a Bose-condensed system is considered. It is shown that a self-consistent treatment of the latter, using a representative ensemble, always yields a conserving and gapless theory.",,9,True
"We use a driven Monte Carlo dynamics in the phase representation to determine the linear resistivity and current-voltage scaling of a two-dimensional Josephson-junction array at an irrational flux quantum per plaquette. The results are consistent with a phase-coherence transition scenario where the critical temperature vanishes. The linear resistivity is nonzero at any finite temperatures but nonlinear behavior sets in at a temperature-dependent crossover current determined by the thermal critical exponent. From a dynamic scaling analysis we determine this critical exponent and the thermally activated behavior of the linear resistivity. The results are in agreement with earlier calculations using the resistively shunted-junction model for the dynamics of the array. The linear resistivity behavior is consistent with some experimental results on arrays of superconducting grains but not on wire networks, which we argue have been obtained in a current regime above the crossover current.","We utilize a driven Monte Carlo dynamics approach in the phase representation to study the linear resistivity and current-voltage scaling of a two-dimensional Josephson-junction array at an irrational flux quantum per plaquette. Our findings support a phase-coherence transition scenario, where the critical temperature tends to zero. The linear resistivity is nonzero at all finite temperatures, but exhibits nonlinear behavior at a temperature-dependent crossover current, as determined by the thermal critical exponent. By performing a dynamic scaling analysis, we extract the critical exponent and the thermally activated behavior of the linear resistivity. Our results align with previous calculations employing the resistively shunted-junction model for the array's dynamics. Notably, the linear resistivity behavior is consistent with experiments on superconducting grain arrays, but disagrees with those on wire networks, which likely operate above the crossover current.",9,False
"The transition between the low density groups of T Tauri stars and the high density clusters around massive stars occurs in the intermediate-mass (IM) range (M$_*$$\\sim$2--8 M$_\\odot$). High spatial resolution studies of IM young stellar objects (YSO) can provide important clues to understand the clustering in massive star forming regions. Aims: Our aim is to search for clustering in IM Class 0 protostars. The high spatial resolution and sensitivity provided by the new A configuration of the Plateau de Bure Interferometer (PdBI) allow us to study the clustering in these nearby objects. Methods: We have imaged three IM Class 0 protostars (Serpens-FIRS 1, IC 1396 N, CB 3) in the continuum at 3.3 and 1.3mm using the PdBI. The sources have been selected with different luminosity to investigate the dependence of the clustering process on the luminosity of the source. Results: Only one millimeter (mm) source is detected towards the low luminosity source Serpens--FIRS 1. Towards CB 3 and IC1396 N, we detect two compact sources separated by $\\sim$0.05 pc. The 1.3mm image of IC 1396 N, which provides the highest spatial resolution, reveal that one of these cores is splitted in, at least, three individual sources.","The transition from low-density groups of T Tauri stars to high-density clusters around massive stars occurs in the intermediate-mass (IM) range (2-8 solar masses). Studying intermediate-mass young stellar objects (YSOs) with high spatial resolution can help us understand clustering in massive star-forming regions. Our goal is to search for clustering in IM Class 0 protostars using the Plateau de Bure Interferometer's (PdBI) high spatial resolution and sensitivity. We imaged three IM Class 0 protostars (Serpens-FIRS 1, IC 1396 N, CB 3) in continuum at 3.3 and 1.3 mm. Source selection was based on luminosity to examine how clustering depends on source luminosity. Only one mm source was detected near Serpens-FIRS 1, while two compact sources were found near CB 3 and IC1396 N, separated by about 0.05 parsecs. The 1.3 mm image of IC 1396 N shows that one core is split into at least three distinct sources, providing valuable information on the clustering process in these objects.",7,False
"To any complex Hadamard matrix H one associates a spin model commuting square, and therefore a hyperfinite subfactor. The standard invariant of this subfactor captures certain \","For each intricate Hadamard matrix H, there corresponds a spin model that squares commutatively and thus yields a hyperfinite subfactor. This subfactor's characteristic invariant encodes information about some crucial features of the original Hadamard matrix.",7,False
"We study electronic transport properties of ferromagnetic nanoparticle arrays and nanodomain materials near the Curie temperature in the limit of weak coupling between the grains. We calculate the conductivity in the Ohmic and non-Ohmic regimes and estimate the magnetoresistance jump in the resistivity at the transition temperature. The results are applicable for many emerging materials, including artificially self-assembled nanoparticle arrays and a certain class of manganites, where localization effects within the clusters can be neglected.","We investigate the electronic transport characteristics of ferromagnetic nanoparticle arrays and nanodomain materials at temperatures close to the Curie temperature, when the interaction between the grains is weak. We determine the conductivity in both Ohmic and non-Ohmic regimes and evaluate the change in resistance at the transition temperature, known as the magnetoresistance jump. Our findings have implications for various developing materials, such as artificially self-assembled nanoparticle arrays and specific manganites, where localization effects within the clusters can be disregarded.",9,False
"We study the dynamical process of disentanglement of two qubits and two qutrits coupled to an Ising spin chain in a transverse field, which exhibits a quantum phase transition. We use the concurrence and negativity to quantify entanglement of two qubits and two qutrits, respectively. Explicit connections between the concurrence (negativity) and the decoherence factors are given for two initial states, the pure maximally entangled state and the mixed Werner state. We find that the concurrence and negativity decay exponentially with fourth power of time in the vicinity of critical point of the environmental system.","The dynamics of disentanglement among two qubits and two qutrits interacting with an Ising spin chain in a transverse field is investigated, specifically focusing on the role of quantum phase transitions. Quantifying entanglement for these systems, we utilize concurrency for qubits and negativity for qutrits. For two specific initial states - the pure maximally entangled state and the mixed Werner state - explicit relationships between concurrency and decoherence factors are derived. Our findings indicate that near the critical point of the environment, both concurrency and negativity decrease exponentially with time, at a rate that is squared four times faster than the rate observed far from the critical point.",6,False
"A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to-leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is demonstrated with data from the Fermilab Tevatron, and predictions are made for more detailed tests with CDF and DO data. Predictions are shown for distributions of diphoton pairs produced at the energy of the Large Hadron Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs boson are contrasted with those produced from QCD processes at the LHC, showing that enhanced sensitivity to the signal can be obtained with judicious selection of events.","A comprehensive study of massive photon pair production in perturbative quantum chromodynamics (QCD) has been performed, taking into account all relevant next-to-leading order perturbative contributions from various subprocesses, including quark-antiquark, gluon-(anti)quark, and gluon-gluon interactions. Additionally, an all-orders resummation of initial-state gluon radiation has been incorporated, ensuring high accuracy at next-to-next-to-leading logarithmic level. The calculated results have been found to be in good agreement with experimental data from the Fermilab Tevatron, and predictions have been made for further testing with CDF and DO data. Furthermore, predictions for diphoton pair production at the Large Hadron Collider (LHC) have been provided, allowing for a comparison between the signals of a hypothetical Higgs boson decay and QCD processes at the LHC. By carefully selecting event samples, the study demonstrates how the sensitivity to the Higgs boson signal can be improved.",9,False
"We describe a new algorithm, the $(k,\\ell)$-pebble game with colors, and use it obtain a characterization of the family of $(k,\\ell)$-sparse graphs and algorithmic solutions to a family of problems concerning tree decompositions of graphs. Special instances of sparse graphs appear in rigidity theory and have received increased attention in recent years. In particular, our colored pebbles generalize and strengthen the previous results of Lee and Streinu and give a new proof of the Tutte-Nash-Williams characterization of arboricity. We also present a new decomposition that certifies sparsity based on the $(k,\\ell)$-pebble game with colors. Our work also exposes connections between pebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and Westermann and Hendrickson.","We introduce a novel algorithm called the $(k, \ell)$-pebble game with colors, which enables us to comprehensively describe the family of $(k, \ell)$-sparse graphs and devise efficient solutions for related tree decomposition problems. Sparse graphs have been gaining traction in recent years, especially in rigidity theory, making our work particularly relevant. Notably, our approach enhances and generalizes previous research by Lee and Streinu, providing a fresh perspective on the classic Tutte-Nash-Williams characterization of arboricity. Additionally, we develop a new decomposition technique that relies on the $(k, \ell)$-pebble game with colors to verify sparsity. Our findings also reveal intriguing links between pebble game algorithms and earlier works by Gabow, Gabow and Westermann, as well as Hendrickson, further enriching the field of sparse graph theory.",10,False
"The evolution of Earth-Moon system is described by the dark matter field fluid model proposed in the Meeting of Division of Particle and Field 2004, American Physical Society. The current behavior of the Earth-Moon system agrees with this model very well and the general pattern of the evolution of the Moon-Earth system described by this model agrees with geological and fossil evidence. The closest distance of the Moon to Earth was about 259000 km at 4.5 billion years ago, which is far beyond the Roche's limit. The result suggests that the tidal friction may not be the primary cause for the evolution of the Earth-Moon system. The average dark matter field fluid constant derived from Earth-Moon system data is 4.39 x 10^(-22) s^(-1)m^(-1). This model predicts that the Mars's rotation is also slowing with the angular acceleration rate about -4.38 x 10^(-22) rad s^(-2).","The Earth-Moon system's development is consistent with the dark matter field fluid model presented at the 2004 American Physical Society's Division of Particle and Field meeting. The model accurately describes the Moon's current behavior and its overall evolutionary pattern, which correlates well with geological and fossil records. Notably, the Moon was once only 259,000 kilometers away from Earth around 4.5 billion years ago—well beyond Roche's limit. These findings suggest that tidal friction might not have been the main driver of the Earth-Moon system's evolution. In addition, the study yielded a constant for the average dark matter field fluid of approximately 4.39 x 10^(-22) s^(-1) m^(-1), which predicts that Mars' rotation is decelerating with an angular acceleration rate of around -4.38 x 10^(-22) rad s^(-2).",10,False
We show that a determinant of Stirling cycle numbers counts unlabeled acyclic single-source automata. The proof involves a bijection from these automata to certain marked lattice paths and a sign-reversing involution to evaluate the determinant.,"We demonstrate that a specific quantity known as the determinant of Stirling cycle numbers is actually a counter for unlabeled acyclic single-source automata. Our proof utilizes a clever mapping between these automata and certain pathways in a lattice, along with a technique called sign-reversing involution to calculate the value of the determinant.",10,False
"In this paper we show how to compute the $\\Lambda_{\\alpha}$ norm, $\\alpha\\ge 0$, using the dyadic grid. This result is a consequence of the description of the Hardy spaces $H^p(R^N)$ in terms of dyadic and special atoms.","In this study, we demonstrate how to calculate the $\\Lambda_{\\alpha}$ norm, where $\\alpha$ is non-negative, by utilizing the dyadic grid. This achievement stems from our understanding of the relationship between the Hardy spaces $H^p(R^N)$ and both dyadic and special atoms.",10,False
"We study the two-particle wave function of paired atoms in a Fermi gas with tunable interaction strengths controlled by Feshbach resonance. The Cooper pair wave function is examined for its bosonic characters, which is quantified by the correction of Bose enhancement factor associated with the creation and annihilation composite particle operators. An example is given for a three-dimensional uniform gas. Two definitions of Cooper pair wave function are examined. One of which is chosen to reflect the off-diagonal long range order (ODLRO). Another one corresponds to a pair projection of a BCS state. On the side with negative scattering length, we found that paired atoms described by ODLRO are more bosonic than the pair projected definition. It is also found that at $(k_F a)^{-1} \\ge 1$, both definitions give similar results, where more than 90% of the atoms occupy the corresponding molecular condensates.","In this study, we investigate the two-particle wave function of pairs of atoms in a Fermi gas whose interactions can be adjusted using Feshbach resonance. We focus on the Cooper pair wave function and examine its bosonic characteristics by analyzing the Bose enhancement factor associated with the creation and annihilation of composite particles. To illustrate our findings, we consider a three-dimensional uniform gas and compare two different definitions of the Cooper pair wave function. One definition is chosen to capture the off-diagonal long-range order (ODLRO), while the other corresponds to a pair projection of a BCS state. Our results show that, for negative scattering lengths, the ODLRO definition leads to a more bosonic behavior compared to the pair-projected definition. Additionally, we find that both definitions yield similar results when the inverse of the Fermi momentum ($(k_F a)^{-1}$) is greater than or equal to 1, indicating that over 90% of the atoms occupy the corresponding molecular condensates.",9,False
"A rather non-standard quantum representation of the canonical commutation relations of quantum mechanics systems, known as the polymer representation has gained some attention in recent years, due to its possible relation with Planck scale physics. In particular, this approach has been followed in a symmetric sector of loop quantum gravity known as loop quantum cosmology. Here we explore different aspects of the relation between the ordinary Schroedinger theory and the polymer description. The paper has two parts. In the first one, we derive the polymer quantum mechanics starting from the ordinary Schroedinger theory and show that the polymer description arises as an appropriate limit. In the second part we consider the continuum limit of this theory, namely, the reverse process in which one starts from the discrete theory and tries to recover back the ordinary Schroedinger quantum mechanics. We consider several examples of interest, including the harmonic oscillator, the free particle and a simple cosmological model.","The polymer representation of quantum mechanics, a less conventional interpretation of the canonical commutation relations, has garnered attention in recent years for its potential connection to Planck scale physics. This approach has been explored in the context of loop quantum gravity, specifically within the realm of loop quantum cosmology. Our study delves into the relationship between traditional Schrödinger theory and the polymer description. The paper consists of two main sections. Firstly, we derive the polymer quantum mechanics from the standard Schrödinger theory and demonstrate how the polymer picture emerges as an appropriate limit. In the second part, we examine the continuum limit of this theory by attempting to retrieve classical Schrödinger quantum mechanics from the discrete theory. We investigate various examples, including the harmonic oscillator, the free particle, and a simplified cosmological model.",8,False
"A general formulation was developed to represent material models for applications in dynamic loading. Numerical methods were devised to calculate response to shock and ramp compression, and ramp decompression, generalizing previous solutions for scalar equations of state. The numerical methods were found to be flexible and robust, and matched analytic results to a high accuracy. The basic ramp and shock solution methods were coupled to solve for composite deformation paths, such as shock-induced impacts, and shock interactions with a planar interface between different materials. These calculations capture much of the physics of typical material dynamics experiments, without requiring spatially-resolving simulations. Example calculations were made of loading histories in metals, illustrating the effects of plastic work on the temperatures induced in quasi-isentropic and shock-release experiments, and the effect of a phase transition.","A universal approach was created to describe material behavior under dynamic loading conditions. This involved developing numerical techniques to compute responses to shock and ramp compressions, as well as ramp decompressions. These methods were successful in extending earlier solutions for scalar equations of state and demonstrated great adaptability and reliability. They also showed excellent agreement with theoretical predictions. The basic techniques for ramp and shock solutions were combined to model complex deformation processes, including shock-induced impacts and interactions between various materials at an interface. These computations effectively captured the essence of material dynamics experiments while eliminating the need for detailed spatial simulations. Sample calculations using metals illustrated how plastic work affects temperature changes during quasi-isentropic and shock-release experiments, as well as the influence of a phase transformation.",9,False
"We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy observations of the Serpens star-forming region. In particular we present a set of criteria for isolating bona fide young stellar objects, YSO's, from the extensive background contamination by extra-galactic objects. We then discuss the properties of the resulting high confidence set of YSO's. We find 235 such objects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An additional set of 51 lower confidence YSO's outside this area is identified from the MIPS data combined with 2MASS photometry. We describe two sets of results, color-color diagrams to compare our observed source properties with those of theoretical models for star/disk/envelope systems and our own modeling of the subset of our objects that appear to be star+disks. These objects exhibit a very wide range of disk properties, from many that can be fit with actively accreting disks to some with both passive disks and even possibly debris disks. We find that the luminosity function of YSO's in Serpens extends down to at least a few x .001 Lsun or lower for an assumed distance of 260 pc. The lower limit may be set by our inability to distinguish YSO's from extra-galactic sources more than by the lack of YSO's at very low luminosities. A spatial clustering analysis shows that the nominally less-evolved YSO's are more highly clustered than the later stages and that the background extra-galactic population can be fit by the same two-point correlation function as seen in other extra-galactic studies. We also present a table of matches between several previous infrared and X-ray studies of the Serpens YSO population and our Spitzer data set.","We examine the outcomes of the joint IRAC and MIPS Spitzer Legacy observations of the Serpens star-forming region, focusing on identifying genuine young stellar objects (YSOs) amidst the abundant background contamination from extragalactic objects. We establish a set of criteria to separate YSOs from the latter and explore the characteristics of the remaining high-confidence YSO sample. Within the 0.85 square degree area covered by both IRAC and MIPS, we identify 235 YSOs, while an additional 51 lower-confidence YSOs are found outside this region using MIPS data combined with 2MASS photometry. Our study produces two main sets of results: color-color diagrams comparing our observed source properties with theoretical models for star/disk/envelope systems, and our own modeling of a subset of YSOs that display properties consistent with star+disk systems. These objects reveal a diverse range of disk properties, including actively accreting disks, passive disks, and potentially debris disks. The luminosity function of YSOs in Serpens extends down to around a few times 0.001 solar luminosities, assuming a distance of 260 parsecs. However, this lower limit might be influenced by our inability to differentiate YSOs from extragalactic sources rather than the actual absence of YSOs at very low luminosities. Furthermore, we perform a spatial clustering analysis that indicates that the less evolved YSOs are more densely grouped compared to their more advanced counterparts, and demonstrate that the background extragalactic population follows the same two-point correlation function as observed in other studies. Finally, we provide a table matching various previous infrared and X-ray investigations of the Serpens YSO population with our Spitzer dataset.",6,False
"Partial cubes are isometric subgraphs of hypercubes. Structures on a graph defined by means of semicubes, and Djokovi\\'{c}'s and Winkler's relations play an important role in the theory of partial cubes. These structures are employed in the paper to characterize bipartite graphs and partial cubes of arbitrary dimension. New characterizations are established and new proofs of some known results are given. The operations of Cartesian product and pasting, and expansion and contraction processes are utilized in the paper to construct new partial cubes from old ones. In particular, the isometric and lattice dimensions of finite partial cubes obtained by means of these operations are calculated.","Partial cubes are subgraphs of hypercubes that share the same symmetries and properties as their parent structure. Semicubes, which are formed by combining smaller cubes, are used to define structures on a graph. Two important concepts in the study of partial cubes are Djokovi's and Winkler's relations. Researchers use these ideas to better understand the characteristics of bipartite graphs and partial cubes with varying dimensionality. This knowledge allows for the development of novel approaches to identifying and categorizing such graphs.",5,False
"The research involves creating new partial cubes through the combination of existing ones using techniques like the Cartesian product and pasting, or expanding and contracting them. By doing so, we can determine the exact dimensions of the resulting partial cubes, both in terms of their isometry group and their position within a larger lattice.",,0,True
"In this paper we present an algorithm for computing Hecke eigensystems of Hilbert-Siegel cusp forms over real quadratic fields of narrow class number one. We give some illustrative examples using the quadratic field $\\Q(\\sqrt{5})$. In those examples, we identify Hilbert-Siegel eigenforms that are possible lifts from Hilbert eigenforms.","This paper proposes a method for determining the Hecke eigenvalues and their corresponding eigenvectors (Hecke eigensystems) of Hilbert-Siegel cusp forms over real quadratic fields with narrow class number one. The authors provide demonstrations of the algorithm's application by utilizing the quadratic field Q(√5), in which they pinpoint specific Hilbert-Siegel eigenforms that can be lifted from Hilbert eigenforms.",8,False
"Recently, Bruinier and Ono classified cusp forms $f(z) := \\sum_{n=0}^{\\infty} a_f(n)q ^n \\in S_{\\lambda+1/2}(\\Gamma_0(N),\\chi)\\cap \\mathbb{Z}[[q]]$ that does not satisfy a certain distribution property for modulo odd primes $p$. In this paper, using Rankin-Cohen Bracket, we extend this result to modular forms of half integral weight for primes $p \\geq 5$. As applications of our main theorem we derive distribution properties, for modulo primes $p\\geq5$, of traces of singular moduli and Hurwitz class number. We also study an analogue of Newman's conjecture for overpartitions.","Recently, Bruinier and Ono demonstrated that there exist cusp forms $f(z) = \sum_{n=0}^{\infty} a_f(n) q^n \in S_{\lambda+1/2}(\Gamma_0(N),\chi)\cap \mathbb{Z}[[q]]$ that do not possess a specific distribution property for odd prime moduli $p$. Building upon their work, we utilize the Rankin-Cohen Bracket to broaden this result by incorporating modular forms of half-integral weight for primes $p \geq 5$. Our primary theorem yields distribution properties for traces of singular moduli and Hurwitz class numbers modulo such primes $p \geq 5$. Additionally, we explore an analogue of Newman's conjecture pertaining to overpartitions.",9,False
"Serre obtained the p-adic limit of the integral Fourier coefficient of modular forms on $SL_2(\\mathbb{Z})$ for $p=2,3,5,7$. In this paper, we extend the result of Serre to weakly holomorphic modular forms of half integral weight on $\\Gamma_{0}(4N)$ for $N=1,2,4$. A proof is based on linear relations among Fourier coefficients of modular forms of half integral weight. As applications we obtain congruences of Borcherds exponents, congruences of quotient of Eisentein series and congruences of values of $L$-functions at a certain point are also studied. Furthermore, the congruences of the Fourier coefficients of Siegel modular forms on Maass Space are obtained using Ikeda lifting.","Serre previously showed that the p-adic limit of the integral Fourier coefficient of modular forms on $SL_2(\mathbb{Z})$ exists for $p=2,3,5,7$. This paper extends Serre's result to weakly holomorphic modular forms of half integral weight on $\Gamma_{0}(4N)$ for $N=1,2,4$, using linear relations among Fourier coefficients of modular forms of half integral weight. The proof leads to various consequences, including congruences of Borcherds exponents, congruences of quotients of Eisenstein series, and congruences of values of $L$-functions at a specific point. Additionally, the congruences of the Fourier coefficients of Siegel modular forms on Maass space can be derived through Ikeda lifting.",10,False
In this article we discuss a relation between the string topology and differential forms based on the theory of Chen's iterated integrals and the cyclic bar complex.,"The article explores a connection between string topology and differential forms, rooted in Chen's iterated integrals and the cyclic bar complex. This relationship is examined through the lens of the theory of Chen's iterated integrals, which provides a framework for understanding the interaction between string topology and differential forms. The cyclic bar complex, a tool from algebraic topology, also plays a crucial role in elucidating this connection. By delving into these concepts, the article sheds light on the intricate ties between string topology and differential forms.",5,False
"The pure spinor formulation of the ten-dimensional superstring leads to manifestly supersymmetric loop amplitudes, expressed as integrals in pure spinor superspace. This paper explores different methods to evaluate these integrals and then uses them to calculate the kinematic factors of the one-loop and two-loop massless four-point amplitudes involving two and four Ramond states.",The ten-dimensional superstring theory's pure spinor formulation yields supersymmetric loop amplitude expressions that are straightforwardly integrated in a superspace with only spinor coordinates. This research investigates various techniques for evaluating such integrals and applies them to determine the kinematic coefficients of the one-loop and two-loop massless four-point functions involving two or four Ramond particles.,9,False
"In this work, we evaluate the lifetimes of the doubly charmed baryons $\\Xi_{cc}^{+}$, $\\Xi_{cc}^{++}$ and $\\Omega_{cc}^{+}$. We carefully calculate the non-spectator contributions at the quark level where the Cabibbo-suppressed diagrams are also included. The hadronic matrix elements are evaluated in the simple non-relativistic harmonic oscillator model. Our numerical results are generally consistent with that obtained by other authors who used the diquark model. However, all the theoretical predictions on the lifetimes are one order larger than the upper limit set by the recent SELEX measurement. This discrepancy would be clarified by the future experiment, if more accurate experiment still confirms the value of the SELEX collaboration, there must be some unknown mechanism to be explored.","In this study, we investigate the lifetime of three doubly charmed baryons, specifically $\Xi_{cc}^{+}$, $\Xi_{cc}^{++}$, and $\Omega_{cc}^{+}$. We thoroughly examine the non-spectator contributions at the quark level, taking into account Cabibbo-suppressed diagrams. To estimate the hadronic matrix elements, we employ a simplified non-relativistic harmonic oscillator model. Our findings are largely consistent with previous studies that utilized the diquark model. However, our theoretical predictions for the lifetimes are significantly higher than the upper limit established by the latest SELEX measurement. This disparity can only be resolved through future experiments that provide more precise data. If the SELEX collaboration's value is confirmed, it will indicate the presence of an unexplored mechanism.",10,False
"Results from spectroscopic observations of the Intermediate Polar (IP) EX Hya in quiescence during 1991 and 2001 are presented. Spin-modulated radial velocities consistent with an outer disc origin were detected for the first time in an IP. The spin pulsation was modulated with velocities near ~500-600 km/s. These velocities are consistent with those of material circulating at the outer edge of the accretion disc, suggesting corotation of the accretion curtain with material near the Roche lobe radius. Furthermore, spin Doppler tomograms have revealed evidence of the accretion curtain emission extending from velocities of ~500 km/s to ~1000 km/s. These findings have confirmed the theoretical model predictions of King & Wynn (1999), Belle et al. (2002) and Norton et al. (2004) for EX Hya, which predict large accretion curtains that extend to a distance close to the Roche lobe radius in this system. Evidence for overflow stream of material falling onto the magnetosphere was observed, confirming the result of Belle et al. (2005) that disc overflow in EX Hya is present during quiescence as well as outburst. It appears that the hbeta and hgamma spin radial velocities originated from the rotation of the funnel at the outer disc edge, while those of halpha were produced due to the flow of material along the field lines far from the white dwarf (narrow component) and close to the white dwarf (broad-base component), in agreement with the accretion curtain model.","Observations of the Intermediate Polar (IP) EX Hya during periods of quiescence in 1991 and 2001 have yielded new insights into the system's accretion dynamics. For the first time, spin-modulated radial velocities indicative of an outer disk origin were detected in an IP, with velocities ranging from approximately 500-600 km/s. This suggests that the accretion curtain is corotating with material at the outer edge of the disk, near the Roche lobe radius. Additionally, spin Doppler tomograms have revealed emissions from the accretion curtain spanning velocities of 500 km/s to 1000 km/s, supporting the idea of a large accretion curtain extending close to the Roche lobe radius. Further, evidence of an overflow stream of material falling onto the magnetosphere was found, consistent with previous studies. The origins of the spin radial velocities were found to be diverse, with hbeta and hgamma velocities originating from the rotation of the funnel at the outer disc edge, while halpha velocities were produced by material flowing along field lines both far from and close to the white dwarf. These results align with the accretion curtain model and provide further support for the theories proposed by King & Wynn (1999), Belle et al. (2002), and Norton et al. (2004).",7,False
"We give a prescription for how to compute the Callias index, using as regulator an exponential function. We find agreement with old results in all odd dimensions. We show that the problem of computing the dimension of the moduli space of self-dual strings can be formulated as an index problem in even-dimensional (loop-)space. We think that the regulator used in this Letter can be applied to this index problem.","In this letter, we provide a formula for calculating the Callias index by utilizing an exponential function as a regulator. Our approach yields consistent results with previous studies in odd dimensions. Moreover, we demonstrate that the issue of determining the dimension of the moduli space of self-dual strings can be reformulated as an index problem in even-dimensional spaces, specifically in loop spaces. Notably, the regulatory method employed in this letter has potential applications in addressing this index problem.",10,False
"The shape of the hadronic form factor f+(q2) in the decay D0 --> K- e+ nue has been measured in a model independent analysis and compared with theoretical calculations. We use 75 fb(-1) of data recorded by the BABAR detector at the PEPII electron-positron collider. The corresponding decay branching fraction, relative to the decay D0 --> K- pi+, has also been measured to be RD = BR(D0 --> K- e+ nue)/BR(D0 --> K- pi+) = 0.927 +/- 0.007 +/- 0.012. From these results, and using the present world average value for BR(D0 --> K- pi+), the normalization of the form factor at q2=0 is determined to be f+(0)=0.727 +/- 0.007 +/- 0.005 +/- 0.007 where the uncertainties are statistical, systematic, and from external inputs, respectively.","The hadronic form factor f+(q2) in the decay D0 → K- e+ nue has been studied using 75 fb(-1) of data collected by the BABAR detector at the PEPII electron-positron collider. The decay branching fraction, RD, has been measured relative to the decay D0 → K- pi+, and found to be 0.927 ± 0.007 ± 0.012. Using this result and the current global average value for BR(D0 → K- pi+), the normalization of the form factor at q2=0 can be determined as f+(0) = 0.727 ± 0.007 ± 0.005 ± 0.007, where the uncertainties represent statistical, systematic, and external input errors, respectively.",7,False
Spatiotemporal pattern formation in a product-activated enzymic reaction at high enzyme concentrations is investigated. Stochastic simulations show that catalytic turnover cycles of individual enzymes can become coherent and that complex wave patterns of molecular synchronization can develop. The analysis based on the mean-field approximation indicates that the observed patterns result from the presence of Hopf and wave bifurcations in the considered system.,"In a study on spatiotemporal pattern formation in a product-activated enzymatic reaction, researchers used stochastic simulations to investigate how high enzyme concentrations affect the behavior of individual enzymes. They found that the catalytic cycles of these enzymes can become coordinated, leading to intricate patterns of molecular synchrony. By analyzing the data using a mean-field approximation, they determined that these patterns arise from two types of bifurcations - Hopf and wave bifurcations - within the system.",6,False
"We present Lie group integrators for nonlinear stochastic differential equations with non-commutative vector fields whose solution evolves on a smooth finite dimensional manifold. Given a Lie group action that generates transport along the manifold, we pull back the stochastic flow on the manifold to the Lie group via the action, and subsequently pull back the flow to the corresponding Lie algebra via the exponential map. We construct an approximation to the stochastic flow in the Lie algebra via closed operations and then push back to the Lie group and then to the manifold, thus ensuring our approximation lies in the manifold. We call such schemes stochastic Munthe-Kaas methods after their deterministic counterparts. We also present stochastic Lie group integration schemes based on Castell--Gaines methods. These involve using an underlying ordinary differential integrator to approximate the flow generated by a truncated stochastic exponential Lie series. They become stochastic Lie group integrator schemes if we use Munthe-Kaas methods as the underlying ordinary differential integrator. Further, we show that some Castell--Gaines methods are uniformly more accurate than the corresponding stochastic Taylor schemes. Lastly we demonstrate our methods by simulating the dynamics of a free rigid body such as a satellite and an autonomous underwater vehicle both perturbed by two independent multiplicative stochastic noise processes.","We propose a method for solving nonlinear stochastic differential equations (SDEs) with non-commutative vector fields, which describe the evolution of a system on a smooth, finite-dimensional manifold. Our approach leverages the theory of Lie groups and their actions on manifolds. Specifically, given a Lie group action that generates transport along the manifold, we first pull back the SDE's flow on the manifold to the Lie group through this action. Then, we apply the exponential map to pull back the flow to the Lie algebra. By performing closed operations in the Lie algebra, we obtain an approximated version of the stochastic flow, which is then pushed forward to the Lie group and finally to the original manifold. This process ensures that our approximation stays within the manifold. We refer to these methods as stochastic Munthe-Kaas methods, named after their deterministic counterparts. Additionally, we explore stochastic Lie group integration schemes inspired by Castell--Gaines methods. These approaches rely on approximating the flow generated by a truncated stochastic exponential Lie series using an underlying ordinary differential integrator. When utilizing Munthe-Kaas methods as the underlying integrator, they become stochastic Lie group integrator schemes. Notably, certain Castell--Gaines methods exhibit uniform accuracy superiority compared to stochastic Taylor schemes. To illustrate our techniques, we simulate the behavior of a free rigid body (e.g., a satellite or an autonomous underwater vehicle) subject to two independent multiplicative stochastic noise processes.",9,False
"The very nature of the solar chromosphere, its structuring and dynamics, remains far from being properly understood, in spite of intensive research. Here we point out the potential of chromospheric observations at millimeter wavelengths to resolve this long-standing problem. Computations carried out with a sophisticated dynamic model of the solar chromosphere due to Carlsson and Stein demonstrate that millimeter emission is extremely sensitive to dynamic processes in the chromosphere and the appropriate wavelengths to look for dynamic signatures are in the range 0.8-5.0 mm. The model also suggests that high resolution observations at mm wavelengths, as will be provided by ALMA, will have the unique property of reacting to both the hot and the cool gas, and thus will have the potential of distinguishing between rival models of the solar atmosphere. Thus, initial results obtained from the observations of the quiet Sun at 3.5 mm with the BIMA array (resolution of 12 arcsec) reveal significant oscillations with amplitudes of 50-150 K and frequencies of 1.5-8 mHz with a tendency toward short-period oscillations in internetwork and longer periods in network regions. However higher spatial resolution, such as that provided by ALMA, is required for a clean separation between the features within the solar atmosphere and for an adequate comparison with the output of the comprehensive dynamic simulations.","Despite extensive research, the structure and behavior of the solar chromosphere remain poorly understood. However, observations at millimeter wavelengths offer a promising way to address this issue. Sophisticated dynamic models, such as those developed by Carlsson and Stein, suggest that these wavelengths are highly sensitive to dynamic processes in the chromosphere. Specifically, the most informative wavelengths lie between 0.8 and 5.0 millimeters. These observations can potentially distinguish between competing models of the solar atmosphere, thanks to their ability to detect both hot and cool gas. Preliminary data from the BIMA array, which has a resolution of 12 arcseconds, has already revealed notable oscillations with temperatures ranging from 50 to 150 Kelvin and frequencies spanning 1.5 to 8 megahertz, with shorter periods observed in internetwork areas and longer periods in network regions. Nonetheless, higher spatial resolution, such as what ALMA offers, is necessary to clearly separate features within the solar atmosphere and compare them effectively with simulation outputs.",6,False
"The formation of quasi-2D spin-wave waveforms in longitudinally magnetized stripes of ferrimagnetic film was observed by using time- and space-resolved Brillouin light scattering technique. In the linear regime it was found that the confinement decreases the amplitude of dynamic magnetization near the lateral stripe edges. Thus, the so-called effective dipolar pinning of dynamic magnetization takes place at the edges. In the nonlinear regime a new stable spin wave packet propagating along a waveguide structure, for which both transversal instability and interaction with the side walls of the waveguide are important was observed. The experiments and a numerical simulation of the pulse evolution show that the shape of the formed waveforms and their behavior are strongly influenced by the confinement.","The formation of two-dimensional spin-wave waveforms in long, thin strips of ferromagnetic material has been studied using advanced techniques that allow us to observe changes in the magnetic field over time and space. When the magnetic field is applied lengthwise along the strip, we find that the strength of the dynamic magnetization weakens near the edges of the strip. This phenomenon is known as effective dipolar pinning"" and occurs because the magnetic moments at the edges are directed perpendicular to the strip's long axis.",6,False
"When we increase the input power, we enter a nonlinear regime where a novel type of spin wave emerges. These waves travel along the length of the strip and are shaped by the narrow confines of the waveguide. We have observed that the waveform's stability and interactions with the surrounding walls play an essential role in determining its properties. Our experimental results agree well with computer simulations, providing valuable insights into how confinement affects the behavior of these exotic waves.",,0,True
"We present recent advances in understanding of the ground and excited states of the electron-phonon coupled systems obtained by novel methods of Diagrammatic Monte Carlo and Stochastic Optimization, which enable the approximation-free calculation of Matsubara Green function in imaginary times and perform unbiased analytic continuation to real frequencies. We present exact numeric results on the ground state properties, Lehmann spectral function and optical conductivity of different strongly correlated systems: Frohlich polaron, Rashba-Pekar exciton-polaron, pseudo Jahn-Teller polaron, exciton, and interacting with phonons hole in the t-J model.","Recent research has led to significant progress in comprehending the ground and excited states of electron-phonon coupled systems, thanks to innovative methodologies such as Diagrammatic Monte Carlo and Stochastic Optimization. These approaches enable the accurate calculation of Matsubara Green functions in imaginary time, followed by an unbiased analytic continuation to real frequencies. The accuracy of these methods allows for precise numerical calculations of various properties, including ground state characteristics, Lehmann spectral function, and optical conductivity, in diverse strongly correlated systems like Frohlich polaron, Rashba-Pekar exciton-polaron, pseudo Jahn-Teller polaron, exciton, and interacting with phonons hole in the t-J model.",8,False
"We describe a peculiar fine structure acquired by the in-plane optical phonon at the Gamma-point in graphene when it is brought into resonance with one of the inter-Landau-level transitions in this material. The effect is most pronounced when this lattice mode (associated with the G-band in graphene Raman spectrum) is in resonance with inter-Landau-level transitions 0 -> (+,1) and (-,1) -> 0, at a magnetic field B_0 ~ 30 T. It can be used to measure the strength of the electron-phonon coupling directly, and its filling-factor dependence can be used experimentally to detect circularly polarized lattice modes.","In graphene, we observe an unusual phenomenon where the in-plane optical phonon at the Gamma-point exhibits a distinctive fine structure when it resonates with certain inter-Landau-level transitions. This occurs when the lattice mode associated with the G-band in the Raman spectrum is in resonance with transitions between energy levels 0 and (+,1), as well as (-,1) and 0, at a specific magnetic field strength of approximately 30 T. By studying this effect, researchers can directly measure the strength of the electron-phonon interaction. Additionally, the dependence of this phenomenon on filling factor allows for the experimental detection of circularly polarized lattice modes.",7,False
We prove pfaffian and hafnian versions of Lieb's inequalities on determinants and permanents of positive semi-definite matrices. We use the hafnian inequality to improve the lower bound of R\\'ev\\'esz and Sarantopoulos on the norm of a product of linear functionals on a real Euclidean space (this subject is sometimes called the `real linear polarization constant' problem).,"Our research demonstrates that Lieb's inequalities on determinants and permanents of positive semi-definite matrices hold for both Pfaffian and Hafnian cases. Utilizing the Hafnian inequality, we enhance the lower bound of R\*ev\*esz and Sarantopoulos's result regarding the norm of a product of linear functionals in a real Euclidean space, an area often referred to as the real linear polarization constant"" problem.",6,False
"We investigate the effect of tuning the phonon energy on the correlation effects in models of electron-phonon interactions using DMFT. In the regime where itinerant electrons, instantaneous electron-phonon driven correlations and static distortions compete on similar energy scales, we find several interesting results including (1) A crossover from band to Mott behavior in the spectral function, leading to hybrid band/Mott features in the spectral function for phonon frequencies slightly larger than the band width. (2) Since the optical conductivity depends sensitively on the form of the spectral function, we show that such a regime should be observable through the low frequency form of the optical conductivity. (3) The resistivity has a double kondo peak arrangement","We examine how adjusting the phonon energy affects correlation effects in models of electron-phonon interactions using dynamical mean field theory (DMFT). Our investigation reveals various intriguing phenomena when itinerant electrons, instantaneous electron-phonon couplings, and static deformations operate on comparable energy scales. Specifically, we observe a transition from band-like to Mott behavior in the spectral function at moderate phonon frequencies, resulting in unique hybrid band/Mott characteristics. This crossover significantly impacts the optical conductivity, making it potentially detectable via its low-frequency profile. Additionally, our study shows that the resistivity exhibits a distinctive double Kondo peak structure.",8,False
"We show that crystal can trap a broad (x, x', y, y', E) distribution of particles and channel it preserved with a high precision. This sampled-and-hold distribution can be steered by a bent crystal for analysis downstream. In simulations for the 7 TeV Large Hadron Collider, a crystal adapted to the accelerator lattice traps 90% of diffractively scattered protons emerging from the interaction point with a divergence 100 times the critical angle. We set the criterion for crystal adaptation improving efficiency ~100-fold. Proton angles are preserved in crystal transmission with accuracy down to 0.1 microrad. This makes feasible a crystal application for measuring very forward protons at the LHC.","Our research demonstrates that a crystal can effectively confine and guide a wide range of particle distributions, including their position and momentum coordinates, while maintaining a high level of precision. By using a curved crystal, this distributed particle population can be directed towards further analysis. In simulated experiments at the Large Hadron Collider, we found that our specially designed crystal was able to capture 90% of the protons that were deflected through large angles, which is 100 times greater than the critical angle, resulting in an improvement in efficiency of up to 100 fold. Additionally, we showed that the crystal preserves the angles of transmitted protons with an accuracy of less than 0.1 microradians, making it possible to use crystals for measuring extremely forward protons at the LHC.",5,False
"We analyze the possibility of probing non-standard neutrino interactions (NSI, for short) through the detection of neutrinos produced in a future galactic supernova (SN).We consider the effect of NSI on the neutrino propagation through the SN envelope within a three-neutrino framework, paying special attention to the inclusion of NSI-induced resonant conversions, which may take place in the most deleptonised inner layers. We study the possibility of detecting NSI effects in a Megaton water Cherenkov detector, either through modulation effects in the $\\bar\ u_e$ spectrum due to (i) the passage of shock waves through the SN envelope, (ii) the time dependence of the electron fraction and (iii) the Earth matter effects; or, finally, through the possible detectability of the neutronization $\ u_e$ burst. We find that the $\\bar\ u_e$ spectrum can exhibit dramatic features due to the internal NSI-induced resonant conversion. This occurs for non-universal NSI strengths of a few %, and for very small flavor-changing NSI above a few$\\times 10^{-5}$.","In this study, we investigate the potential for observing non-standard neutrino interactions (NSI) during a future galactic supernova (SN) using a Megaton water Cherenkov detector. Specifically, we focus on how NSI affects the propagation of neutrinos through the SN envelope, taking into account the possibility of resonant conversions that may occur in the innermost, deleptonized regions. We examine three different ways to detect NSI effects in the detector: modulations in the electron antineutrino spectrum caused by shock waves passing through the envelope, time variations in the electron fraction, and Earth matter effects; as well as the potential detection of a neutronization burst. Our results show that the electron antineutrino spectrum can display striking features resulting from internal NSI-induced resonant conversion, particularly for non-universal NSI strengths of a few percent and very small flavor-changing NSI above a few times $10^{-5}$.",8,False
"We performed a rigorous theoretical convergence analysis of the discrete dipole approximation (DDA). We prove that errors in any measured quantity are bounded by a sum of a linear and quadratic term in the size of a dipole d, when the latter is in the range of DDA applicability. Moreover, the linear term is significantly smaller for cubically than for non-cubically shaped scatterers. Therefore, for small d errors for cubically shaped particles are much smaller than for non-cubically shaped. The relative importance of the linear term decreases with increasing size, hence convergence of DDA for large enough scatterers is quadratic in the common range of d. Extensive numerical simulations were carried out for a wide range of d. Finally we discuss a number of new developments in DDA and their consequences for convergence.","Our study thoroughly examined the accuracy of the discrete dipole approximation (DDA) through a detailed theoretical analysis. We demonstrated that the error in any calculated quantity is limited to a combination of linear and squared terms related to the dipole's size, providing DDA remains applicable. Notably, the linear component is substantially reduced for cube-shaped objects compared to other shapes. As a result, errors for small dipoles are considerably lower for cubic particles. Furthermore, as the size increases, the significance of the linear term diminishes, resulting in a generally quadratic rate of convergence for larger dipoles within the typical range. To substantiate our findings, extensive numerical experiments spanning various sizes were conducted. Lastly, we discussed novel advancements in DDA and their implications on its convergence behavior.",8,False
"This is a supplement to the paper arXiv:q-bio/0701050, containing the text of correspondence sent to Nature in 1990.","This document serves as an additional resource for the paper titled arXiv:q-bio/0701050"" and includes the contents of letters that were sent to Nature in 1990.",10,False
"We propose an extrapolation technique that allows accuracy improvement of the discrete dipole approximation computations. The performance of this technique was studied empirically based on extensive simulations for 5 test cases using many different discretizations. The quality of the extrapolation improves with refining discretization reaching extraordinary performance especially for cubically shaped particles. A two order of magnitude decrease of error was demonstrated. We also propose estimates of the extrapolation error, which were proven to be reliable. Finally we propose a simple method to directly separate shape and discretization errors and illustrated this for one test case.","Our approach enhances the precision of discrete dipole approximation calculations by employing an innovative extrapolation technique. Through comprehensive simulations across five diverse scenarios, we evaluated the effectiveness of our method using various discretizations. Notably, when applied to cubic-shaped particles, our technique yielded remarkable results, exhibiting a remarkable reduction in error by nearly two orders of magnitude. Additionally, we developed estimators for predicting extrapolation errors, which proved to be dependable. To further facilitate error analysis, we devised a straightforward approach to differentiate between shape and discretization errors. This novel technique was successfully demonstrated through its application to one of the test cases.",9,False
"The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly used in cell signaling. This motif itself can generate a variety of dynamic behaviors like bistability and ultrasensitivity without direct positive feedbacks. In this paper, we study the number of positive steady states of a general multisite phosphorylation-dephosphorylation cycle, and how the number of positive steady states varies by changing the biological parameters. We show analytically that (1) for some parameter ranges, there are at least n+1 (if n is even) or n (if n is odd) steady states; (2) there never are more than 2n-1 steady states (in particular, this implies that for n=2, including single levels of MAPK cascades, there are at most three steady states); (3) for parameters near the standard Michaelis-Menten quasi-steady state conditions, there are at most n+1 steady states; and (4) for parameters far from the standard Michaelis-Menten quasi-steady state conditions, there is at most one steady state.","The repeated use of the multisite phosphorylation-dephosphorylation cycle in cell signaling allows for various dynamic behaviors, such as bistability and ultrasensitivity, to occur without direct positive feedback loops. In this study, we investigate the impact of altering biological parameters on the number of stable states in a generalized multisite phosphorylation-dephosphorylation cycle. Our findings reveal that within certain parameter ranges, the number of stable states increases with the number of sites being modified, while never exceeding 2n-1 states. Notably, when considering systems with two levels of modification (n=2), we discover that there exist no more than three stable states. Furthermore, our analysis shows that under typical Michaelis-Menten quasi-steady state conditions, the number of stable states does not surpass n+1, whereas for parameters significantly deviating from these conditions, only one stable state remains.",9,False
"In this manuscript we investigate the capabilities of the Discrete Dipole Approximation (DDA) to simulate scattering from particles that are much larger than the wavelength of the incident light, and describe an optimized publicly available DDA computer program that processes the large number of dipoles required for such simulations. Numerical simulations of light scattering by spheres with size parameters x up to 160 and 40 for refractive index m=1.05 and 2 respectively are presented and compared with exact results of the Mie theory. Errors of both integral and angle-resolved scattering quantities generally increase with m and show no systematic dependence on x. Computational times increase steeply with both x and m, reaching values of more than 2 weeks on a cluster of 64 processors. The main distinctive feature of the computer program is the ability to parallelize a single DDA simulation over a cluster of computers, which allows it to simulate light scattering by very large particles, like the ones that are considered in this manuscript. Current limitations and possible ways for improvement are discussed.","In this study, we explore the potential of the Discrete Dipole Approximation (DDA) to model the scattering of light by particles that are significantly larger than the wavelength of the incident light. We also describe a freely available computer program that has been optimized to handle the vast number of dipoles required for such simulations. Our numerical experiments involve simulating light scattering by spheres with size parameters up to 160 and 40 for refractive indices of 1.05 and 2, respectively, and comparing the results with those obtained using the exact Mie theory. We find that errors in both integrated and angle-resolved scattering quantities tend to increase with the refractive index, while showing no consistent trend with particle size. Notably, computational time increases sharply with both particle size and refractive index, requiring over two weeks of processing power on a 64-processor cluster. A key feature of our computer program is its ability to distribute a single DDA simulation across multiple processors, enabling the simulation of light scattering by extremely large particles. However, there are still limitations to the current approach, and we discuss potential avenues for improvement.",7,False
"We present a review of the discrete dipole approximation (DDA), which is a general method to simulate light scattering by arbitrarily shaped particles. We put the method in historical context and discuss recent developments, taking the viewpoint of a general framework based on the integral equations for the electric field. We review both the theory of the DDA and its numerical aspects, the latter being of critical importance for any practical application of the method. Finally, the position of the DDA among other methods of light scattering simulation is shown and possible future developments are discussed.","In this article, we provide an overview of the Discrete Dipole Approximation (DDA) method for simulating light scattering by arbitrary-shaped particles. We begin by placing the method within its historical context and highlighting recent advancements. Our approach focuses on the integral equation framework that underlies the DDA, allowing us to thoroughly examine both the theoretical foundations and numerical implementation of the technique. We then discuss the various applications of the DDA and how it compares to alternative methods used in light scattering simulations. Finally, we conclude with a discussion of potential future directions for research involving the DDA.",9,False
"The quadratic pion scalar radius, \\la r^2\a^\\pi_s, plays an important role for present precise determinations of \\pi\\pi scattering. Recently, Yndur\\'ain, using an Omn\\`es representation of the null isospin(I) non-strange pion scalar form factor, obtains \\la r^2\a^\\pi_s=0.75\\pm 0.07 fm^2. This value is larger than the one calculated by solving the corresponding Muskhelishvili-Omn\\`es equations, \\la r^2\a^\\pi_s=0.61\\pm 0.04 fm^2. A large discrepancy between both values, given the precision, then results. We reanalyze Yndur\\'ain's method and show that by imposing continuity of the resulting pion scalar form factor under tiny changes in the input \\pi\\pi phase shifts, a zero in the form factor for some S-wave I=0 T-matrices is then required. Once this is accounted for, the resulting value is \\la r^2\a_s^\\pi=0.65\\pm 0.05 fm^2. The main source of error in our determination is present experimental uncertainties in low energy S-wave I=0 \\pi\\pi phase shifts. Another important contribution to our error is the not yet settled asymptotic behaviour of the phase of the scalar form factor from QCD.","The quadratic pion scalar radius, which refers to the square of the distance between the quark and antiquark within a pion, has significant implications for the accurate study of pion-pion scattering. In recent times, researcher Yndurain utilized an Omnes representation of the null isospin (I) non-strange pion scalar form factor to determine the value of this radius, obtaining a result of approximately 0.75 ± 0.07 femtometer squared (fm^2). However, this value was found to be inconsistent with the value obtained through the solution of the corresponding Muskhelishvili-Omnes equations, which yielded a value of around 0.61 ± 0.04 fm^2. This discrepancy raises questions about the accuracy of the initial result. To address this issue, we conducted a reevaluation of Yndurain's approach, incorporating the requirement of continuity in the resulting pion scalar form factor when there are minor variations in the input pi-pi phase shifts. By doing so, we discovered that a zero in the form factor becomes necessary for certain S-wave I=0 T-matrices. When this constraint is taken into account, the derived value of the quadratic pion scalar radius turns out to be approximately 0.65 ± 0.05 fm^2. The primary source of uncertainty in this determination stems from current experimental uncertainties in low-energy S-wave I=0 pi-pi phase shifts. Additionally, the not-yet-settled nature of the asymptotic behavior of the phase of the scalar form factor from Quantum Chromodynamics (QCD) contributes significantly to the overall error margin.",,
"We formulate a quantum generalization of the notion of the group of Riemannian isometries for a compact Riemannian manifold, by introducing a natural notion of smooth and isometric action by a compact quantum group on a classical or noncommutative manifold described by spectral triples, and then proving the existence of a universal object (called the quantum isometry group) in the category of compact quantum groups acting smoothly and isometrically on a given (possibly noncommutative) manifold satisfying certain regularity assumptions. In fact, we identify the quantum isometry group with the universal object in a bigger category, namely the category of `quantum families of smooth isometries', defined along the line of Woronowicz and Soltan. We also construct a spectral triple on the Hilbert space of forms on a noncommutative manifold which is equivariant with respect to a natural unitary representation of the quantum isometry group. We give explicit description of quantum isometry groups of commutative and noncommutative tori, and in this context, obtain the quantum double torus defined in \\cite{hajac} as the universal quantum group of holomorphic isometries of the noncommutative torus.","We develop a quantum version of the concept of the group of Riemannian isometries for a compact Riemannian manifold by introducing a well-defined and smooth action of a compact quantum group on a classical or noncommutative manifold, described by spectral triples. We prove that there exists a unique object, called the quantum isometry group, in the category of compact quantum groups that act smoothly and isometrically on a given manifold, subject to certain regularity conditions. Furthermore, we show that the quantum isometry group can be identified with an object in a larger category, known as the category of ""quantum families of smooth isometries,"" which was introduced by Woronowicz and Soltan. Additionally, we construct a spectral triple on the Hilbert space of forms on a noncommutative manifold that is equipped with a natural unitary representation of the quantum isometry group. We provide explicit descriptions of quantum isometry groups of both commutative and noncommutative tori, and in doing so, recover the quantum double torus presented in \cite{hajac} as the universal quantum group of holomorphic isometries of the noncommutative torus.",9,False
It is outlined the possibility to extend the quantum formalism in relation to the requirements of the general systems theory. It can be done by using a quantum semantics arising from the deep logical structure of quantum theory. It is so possible taking into account the logical openness relationship between observer and system. We are going to show how considering the truth-values of quantum propositions within the context of the fuzzy sets is here more useful for systemics . In conclusion we propose an example of formal quantum coherence.,"The paper explores the potential to broaden the scope of quantum mechanics to better align with the principles of general systems theory. This is achieved by employing a quantum semantics that leverages the inherent logical structure of quantum theory. By acknowledging the reciprocal relationship between the observer and the system, we demonstrate how assessing the veracity of quantum statements within the framework of fuzzy sets can be beneficial for understanding complex systems. Ultimately, we present a case study illustrating the concept of formal quantum coherence.",9,False
"We report on the analysis of selected single source data sets from the first round of the Mock LISA Data Challenges (MLDC) for white dwarf binaries. We implemented an end-to-end pipeline consisting of a grid-based coherent pre-processing unit for signal detection, and an automatic Markov Chain Monte Carlo post-processing unit for signal evaluation. We demonstrate that signal detection with our coherent approach is secure and accurate, and is increased in accuracy and supplemented with additional information on the signal parameters by our Markov Chain Monte Carlo approach. We also demonstrate that the Markov Chain Monte Carlo routine is additionally able to determine accurately the noise level in the frequency window of interest.","In this study, we examined a few specific datasets from the initial round of the Mock LISA Data Challenges (MLDC) for binary systems containing white dwarfs. Our methodology involved using a comprehensive pipeline that combined a grid-based coherent pre-processing step for detecting signals and an automated Markov Chain Monte Carlo post-processing stage for assessing the detected signals' validity and estimating their characteristics. The results show that our coherent technique reliably and precisely identifies signals, while our Markov Chain Monte Carlo approach enhances the precision and provides more insightful information about the signal properties. Additionally, we found that the Markov Chain Monte Carlo routine can successfully estimate the noise levels within the range of frequencies of interest.",9,False
"We present an algorithm that produces the classification list of smooth Fano d-polytopes for any given d. The input of the algorithm is a single number, namely the positive integer d. The algorithm has been used to classify smooth Fano d-polytopes for d<=7. There are 7622 isomorphism classes of smooth Fano 6-polytopes and 72256 isomorphism classes of smooth Fano 7-polytopes.","Our method yields a classification system for polished Fano d-polytopes, taking in only a single positive integer value, d, as its input. This approach has successfully categorized smooth Fano d-polytopes up to dimension 7, revealing 7622 distinct groups of smooth Fano 6-polytopes and a remarkable 72256 sets of smooth Fano 7-polytopes.",9,False
"Part I describes an intelligent acoustic emission locator, while Part II discusses blind source separation, time delay estimation and location of two continuous acoustic emission sources. Acoustic emission (AE) analysis is used for characterization and location of developing defects in materials. AE sources often generate a mixture of various statistically independent signals. A difficult problem of AE analysis is separation and characterization of signal components when the signals from various sources and the mode of mixing are unknown. Recently, blind source separation (BSS) by independent component analysis (ICA) has been used to solve these problems. The purpose of this paper is to demonstrate the applicability of ICA to locate two independent simultaneously active acoustic emission sources on an aluminum band specimen. The method is promising for non-destructive testing of aircraft frame structures by acoustic emission analysis.","This paper is divided into two parts. The first part focuses on an intelligent acoustic emission locator, while the second part covers blind source separation, time delay estimation, and location of two continuous acoustic emission sources. Acoustic emission analysis is commonly used to identify and locate developing flaws in materials. However, it can be challenging to separate and characterize signal components when the sources are unknown and generate a mix of different signals. To address this issue, the paper explores the use of blind source separation through independent component analysis. The goal is to demonstrate the effectiveness of this approach in locating two independently active acoustic emission sources on an aluminum band specimen, which could have important applications in non-destructive testing of aircraft frame structures using acoustic emission analysis.",6,False
"A novel way of picturing the processing of quantum information is described, allowing a direct visualization of teleportation of quantum states and providing a simple and intuitive understanding of this fascinating phenomenon. The discussion is aimed at providing physicists a method of explaining teleportation to non-scientists. The basic ideas of quantum physics are first explained in lay terms, after which these ideas are used with a graphical description, out of which teleportation arises naturally.","A new approach to visualizing the handling of quantum data is presented, enabling a clear depiction of quantum state teleportation and offering an accessible explanation of this intriguing phenomenon. This approach is intended for physicists who want to explain teleportation to people without a scientific background. First, the fundamental principles of quantum mechanics are explained in straightforward language, followed by a graphical representation that organically leads to the concept of teleportation.",7,False
"We study space-time symmetries in scalar quantum field theory (including interacting theories) on static space-times. We first consider Euclidean quantum field theory on a static Riemannian manifold, and show that the isometry group is generated by one-parameter subgroups which have either self-adjoint or unitary quantizations. We analytically continue the self-adjoint semigroups to one-parameter unitary groups, and thus construct a unitary representation of the isometry group of the associated Lorentzian manifold. The method is illustrated for the example of hyperbolic space, whose Lorentzian continuation is Anti-de Sitter space.","In the realm of scalar quantum field theory, we delve into the study of space-time symmetries, encompassing both non-interacting and interacting models, on static spacetimes. Our initial focus lies with Euclidean quantum field theory on a static Riemannian manifold, where we demonstrate that the isometry group is fueled by one-parameter subgroups that give rise to either self-adjoint or unitary quantizations. By employing an analytical continuation of the self-adjoint semigroups, we successfully transform them into one-parameter unitary groups, thereby establishing a unitary representation of the isometry group linked to the corresponding Lorentzian manifold. To illustrate our approach, we utilize the paradigm of hyperbolic space, whose Lorentzian counterpart takes the form of Anti-de Sitter space.",10,False
"The aim of the present paper is to provide a global presentation of the theory of special Finsler manifolds. We introduce and investigate globally (or intrinsically, free from local coordinates) many of the most important and most commonly used special Finsler manifolds: locally Minkowskian, Berwald, Landesberg, general Landesberg, $P$-reducible, $C$-reducible, semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent, $C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like, $R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant curvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global definitions of these special Finsler manifolds are introduced. Various relationships between the different types of the considered special Finsler manifolds are found. Many local results, known in the literature, are proved globally and several new results are obtained. As a by-product, interesting identities and properties concerning the torsion tensor fields and the curvature tensor fields are deduced. Although our investigation is entirely global, we provide; for comparison reasons, an appendix presenting a local counterpart of our global approach and the local definitions of the special Finsler spaces considered.","The current paper aspires to deliver a comprehensive overview of the theory of special Finsler manifolds, encompassing various significant and widely used types. The authors' approach is inherently global, eschewing local coordinate systems. They introduce and examine numerous notable Finsler manifolds, including those that are locally Minkowskian, Berwald, Landesberg, general Landesberg, $P$-reducible, $C$-reducible, semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent, $C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like, $R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant curvature, of $p$-scalar curvature, and of $s$-$ps$-curvature. Through their global approach, the authors establish connections between these diverse types of Finsler manifolds, uncovering both familiar and novel relationships. By leveraging their global perspective, they manage to prove certain local results and unearth fresh insights. Additionally, they derive valuable identities and characteristics related to torsion and curvature tensor fields as a byproduct of their research. To facilitate comparisons, the authors include an appendix outlining a local analogue of their global methodology and defining the special Finsler spaces under consideration.",8,False
"In this paper we consider the Hardy-Lorentz spaces $H^{p,q}(R^n)$, with $0<p\\le 1$, $0<q\\le \\infty$. We discuss the atomic decomposition of the elements in these spaces, their interpolation properties, and the behavior of singular integrals and other operators acting on them.","In this study, we focus on the Hardy-Lorentz spaces $H^{p,q}(\mathbb{R}^n)$, where $0 < p \leq 1$ and $0 < q \leq \infty$. Our aim is to provide an in-depth examination of the atomic decomposition of elements within these spaces, as well as their interpolation characteristics. Additionally, we investigate how singular integrals and various operators behave when applied to functions from these spaces.",8,False
"Potassium intercalation in graphite is investigated by first-principles theory. The bonding in the potassium-graphite compound is reasonably well accounted for by traditional semilocal density functional theory (DFT) calculations. However, to investigate the intercalate formation energy from pure potassium atoms and graphite requires use of a description of the graphite interlayer binding and thus a consistent account of the nonlocal dispersive interactions. This is included seamlessly with ordinary DFT by a van der Waals density functional (vdW-DF) approach [Phys. Rev. Lett. 92, 246401 (2004)]. The use of the vdW-DF is found to stabilize the graphite crystal, with crystal parameters in fair agreement with experiments. For graphite and potassium-intercalated graphite structural parameters such as binding separation, layer binding energy, formation energy, and bulk modulus are reported. Also the adsorption and sub-surface potassium absorption energies are reported. The vdW-DF description, compared with the traditional semilocal approach, is found to weakly soften the elastic response.","Potassium's ability to insert itself into graphite is looked at using first-principles theory. Traditional semi-local density functional theory (DFT) calculations do a good job of explaining the bonding in the potassium-graphite compound. But to figure out how much energy it takes to make an intercalate from pure potassium atoms and graphite, you need a way to describe the binding between the graphite layers that includes non-local dispersive interactions. A van der Waals density functional (vdW-DF) method does this without any problems and includes these interactions in a natural way along with regular DFT. Using the vdW-DF method makes the graphite crystal more stable, which agrees fairly well with what has been seen in real life. They also say that things like the distance between bindings, the energy it takes to form a layer, and the amount of energy it takes to put potassium under the surface are all affected by the vdW-DF description. Compared to the traditional semilocal approach, the vdW-DF description makes the elastic response less strong.",7,False
"We study a simple model of a nematic liquid crystal made of parallel ellipsoidal particles interacting via a repulsive Gaussian law. After identifying the relevant solid phases of the system through a careful zero-temperature scrutiny of as many as eleven candidate crystal structures, we determine the melting temperature for various pressure values, also with the help of exact free energy calculations. Among the prominent features of this model are pressure-driven reentrant melting and the stabilization of a columnar phase for intermediate temperatures.","In this research, we investigate a basic model of a nematic liquid crystal composed of rod-shaped particles that interact with each other through a repulsive potential. We first examine the system at absolute zero temperature to identify the different possible solid phases it can adopt. By carefully analyzing eleven distinct crystal structures, we identify the conditions under which each one is stable. Next, we use precise calculations of the free energy to determine the temperature at which the material melts for various pressures. Our findings reveal several intriguing aspects of the model's behavior, including the phenomenon of reentrant melting, where the material's melting point changes with pressure, and the emergence of a columnar phase at intermediate temperatures.",4,False
"We study the interplay of crystal field splitting and Hund coupling in a two-orbital model which captures the essential physics of systems with two electrons or holes in the e_g shell. We use single site dynamical mean field theory with a recently developed impurity solver which is able to access strong couplings and low temperatures. The fillings of the orbitals and the location of phase boundaries are computed as a function of Coulomb repulsion, exchange coupling and crystal field splitting. We find that the Hund coupling can drive the system into a novel Mott insulating phase with vanishing orbital susceptibility. Away from half-filling, the crystal field splitting can induce an orbital selective Mott state.","In this research, we investigate the interaction between crystal field splitting and Hund coupling in a two-orbital model, which accurately represents the fundamental physics of systems containing two electrons or holes in the e_g shell. Utilizing single site dynamical mean field theory and a cutting-edge impurity solver capable of handling strong couplings and low temperatures, we analyze how the fillings of the orbitals and the positions of phase boundaries change as a function of Coulomb repulsion, exchange coupling, and crystal field splitting. Our findings reveal that the Hund coupling has the ability to drive the system into a previously unobserved Mott insulating phase characterized by zero orbital susceptibility. Moreover, away from half-filling, the crystal field splitting can result in an orbital selective Mott state.",10,False
"I shall present three arguments for the proposition that intelligent life is very rare in the universe. First, I shall summarize the consensus opinion of the founders of the Modern Synthesis (Simpson, Dobzhanski, and Mayr) that the evolution of intelligent life is exceedingly improbable. Second, I shall develop the Fermi Paradox: if they existed they'd be here. Third, I shall show that if intelligent life were too common, it would use up all available resources and die out. But I shall show that the quantum mechanical principle of unitarity (actually a form of teleology!) requires intelligent life to survive to the end of time. Finally, I shall argue that, if the universe is indeed accelerating, then survival to the end of time requires that intelligent life, though rare, to have evolved several times in the visible universe. I shall argue that the acceleration is a consequence of the excess of matter over antimatter in the universe. I shall suggest experiments to test these claims.","The possibility that intelligent life exists abundantly throughout the cosmos will be challenged by offering three compelling arguments to the contrary. We'll begin with the collective viewpoint of influential figures like Simpson, Dobzhansky, and Mayr, who assert that the development of sophisticated life forms is highly implausible from an evolutionary standpoint. Then we'll delve into the Fermi Paradox, which questions why, given their presumed existence, advanced civilizations haven't yet made contact or revealed themselves. Moving on, we'll demonstrate how the widespread presence of intelligent life would lead to resource depletion and eventual extinction. However, we'll also explore how the quantum mechanical concept of unitarity – which has teleological aspects – necessitates the long-term survival of intelligent life. Lastly, we'll propose that the observed acceleration of the universe can only be explained by an imbalance of matter and antimatter, and that this, in turn, suggests the emergence of intelligent life multiple times within our observable universe. To validate these hypotheses, we'll outline experimental methods worth considering.",10,False
"We investigate the Coulomb excitation of low-lying states of unstable nuclei in intermediate energy collisions ($E_{lab}\\sim10-500$ MeV/nucleon). It is shown that the cross sections for the $E1$ and $E2$ transitions are larger at lower energies, much less than 10 MeV/nucleon. Retardation effects and Coulomb distortion are found to be both relevant for energies as low as 10 MeV/nucleon and as high as 500 MeV/nucleon. Implications for studies at radioactive beam facilities are discussed.","We explore the Coulomb excitation of low-energy states in unstable nuclei during intermediate-energy collisions (with laboratory energies ranging from approximately 10 to 500 MeV per nucleon). Our findings indicate that the cross sections for electric dipole (E1) and electric quadrupole (E2) transitions decrease with increasing energy, becoming significantly smaller above 10 MeV/nucleon. However, we observe that both retardation effects and Coulomb distortion play a significant role in these interactions, regardless of whether the energy is as low as 10 MeV/nucleon or as high as 500 MeV/nucleon. These results have important implications for future research at radioactive beam facilities.",7,False
"Intersection bodies represent a remarkable class of geometric objects associated with sections of star bodies and invoking Radon transforms, generalized cosine transforms, and the relevant Fourier analysis. The main focus of this article is interrelation between generalized cosine transforms of different kinds in the context of their application to investigation of a certain family of intersection bodies, which we call $\\lam$-intersection bodies. The latter include $k$-intersection bodies (in the sense of A. Koldobsky) and unit balls of finite-dimensional subspaces of $L_p$-spaces. In particular, we show that restrictions onto lower dimensional subspaces of the spherical Radon transforms and the generalized cosine transforms preserve their integral-geometric structure. We apply this result to the study of sections of $\\lam$-intersection bodies. New characterizations of this class of bodies are obtained and examples are given. We also review some known facts and give them new proofs.","Intersection bodies, a fascinating class of geometric objects, are closely linked to sectioning star bodies and utilize Radon transforms, generalized cosine transforms, and related Fourier analysis. This article centers on the relationship between various types of generalized cosine transforms when applied to investigate a specific set of intersection bodies, dubbed $\ Lam$-intersection bodies. Notably, these bodies encompass $ k $-intersection bodies (as defined by A. Koldobsky) and unit balls of finite-dimensional subspaces within $ L_p $-spaces. Our research reveals that restricting the spherical Radon transforms and generalized cosine transforms to lower-dimensional subspaces preserves their integral-geometric essence. By applying this insight, we delve into the study of sections of $\ Lam$-intersection bodies, leading to fresh characterizations and illustrative examples. Additionally, we revisit established facts and offer novel proof approaches.",8,False
"In this paper, we introduce the on-line Viterbi algorithm for decoding hidden Markov models (HMMs) in much smaller than linear space. Our analysis on two-state HMMs suggests that the expected maximum memory used to decode sequence of length $n$ with $m$-state HMM can be as low as $\\Theta(m\\log n)$, without a significant slow-down compared to the classical Viterbi algorithm. Classical Viterbi algorithm requires $O(mn)$ space, which is impractical for analysis of long DNA sequences (such as complete human genome chromosomes) and for continuous data streams. We also experimentally demonstrate the performance of the on-line Viterbi algorithm on a simple HMM for gene finding on both simulated and real DNA sequences.","In this study, we present an innovative approach to decoding hidden Markov models (HMMs) using the online Viterbi algorithm, which requires significantly less space than traditional methods. Specifically, our analysis shows that the expected maximum memory usage for decoding a sequence of length n with an m-state HMM can be reduced to O(m log n), without sacrificing performance. This represents a substantial improvement over the classical Viterbi algorithm, which necessitates O(mn) space and becomes impractical when dealing with large datasets such as entire human genome chromosomes or continuous data streams. To validate our findings, we have conducted experiments utilizing a simplified HMM for gene discovery on both synthetic and actual DNA sequences, demonstrating the efficiency and effectiveness of our novel method.",7,False
"Neutrinoless double beta decay is one of the most sensitive approaches in non-accelerator particle physics to take us into a regime of physics beyond the standard model. This article is a brief review of the experiments in search of neutrinoless double beta decay from 76Ge. Following a brief introduction of the process of double beta decay from 76Ge, the results of the very first experiments IGEX and Heidelberg-Moscow which give indications of the existence of possible neutrinoless double beta decay mode has been reviewed. Then ongoing efforts to substantiate the early findings are presented and the Majorana experiment as a future experimental approach which will allow a very detailed study of the neutrinoless decay mode is discussed.","Neutrinoless double beta decay offers a unique opportunity to explore physics beyond the Standard Model without relying on high-energy accelerators. In this article, we provide an overview of past and present attempts to detect neutrinoless double beta decay in germanium-76 (76Ge). We begin by introducing the concept of double beta decay and its potential significance in advancing our understanding of particle physics. Next, we examine the pioneering experiments conducted by the IGEX and Heidelberg-Moscow collaborations, which provided initial hints of the possibility of neutrinoless double beta decay. We then discuss ongoing efforts to verify these findings and elaborate on the cutting-edge Majorana experiment, which promises to shed light on the elusive neutrinoless decay mode.",7,False
"We capture the off-shell as well as the on-shell nilpotent Becchi-Rouet-Stora-Tyutin (BRST) and anti-BRST symmetry invariance of the Lagrangian densities of the four (3 + 1)-dimensional (4D) (non-)Abelian 1-form gauge theories within the framework of the superfield formalism. In particular, we provide the geometrical interpretations for (i) the above nilpotent symmetry invariance, and (ii) the above Lagrangian densities, in the language of the specific quantities defined in the domain of the above superfield formalism. Some of the subtle points, connected with the 4D (non-)Abelian 1-form gauge theories, are clarified within the framework of the above superfield formalism where the 4D ordinary gauge theories are considered on the (4, 2)-dimensional supermanifold parametrized by the four spacetime coordinates x^\\mu (with \\mu = 0, 1, 2, 3) and a pair of Grassmannian variables \\theta and \\bar\\theta. One of the key results of our present investigation is a great deal of simplification in the geometrical understanding of the nilpotent (anti-)BRST symmetry invariance.","We investigate (3+1)-dimensional non-Abelian 1-form gauge theories using the superfield formalism, which enables us to simultaneously capture both on-shell and off-shell BRST and anti-BRST symmetries. Within this framework, we provide geometric interpretations for these symmetries and the associated Lagrangian densities. Our approach sheds light on certain nuances peculiar to 4D non-Abelian 1-form gauge theories, significantly simplifying their geometric understanding. Notably, our work reveals novel insights into the relationship between the nilpotent (anti-)BRST symmetry and the underlying geometry of the 4D, (4, 2)-dimensional supermanifold, whose coordinates include four spacetime coordinates xμ (μ=0,1,2,3) and a pair of Grassmann variables θ and θ̄.",9,False
We introduce a family of rings of symmetric functions depending on an infinite sequence of parameters. A distinguished basis of such a ring is comprised by analogues of the Schur functions. The corresponding structure coefficients are polynomials in the parameters which we call the Littlewood-Richardson polynomials. We give a combinatorial rule for their calculation by modifying an earlier result of B. Sagan and the author. The new rule provides a formula for these polynomials which is manifestly positive in the sense of W. Graham. We apply this formula for the calculation of the product of equivariant Schubert classes on Grassmannians which implies a stability property of the structure coefficients. The first manifestly positive formula for such an expansion was given by A. Knutson and T. Tao by using combinatorics of puzzles while the stability property was not apparent from that formula. We also use the Littlewood-Richardson polynomials to describe the multiplication rule in the algebra of the Casimir elements for the general linear Lie algebra in the basis of the quantum immanants constructed by A. Okounkov and G. Olshanski.,"We present a family of rings of symmetric functions, each dependent on an endless sequence of parameters. A set of Schur function analogs serves as a preferred foundation for such a ring. The Littlewood-Richardson polynomials, which are polynomial in the parameters, define the structural constants of this ring. We have devised a combinatorial technique for determining these numbers, which involves altering a previous B. Sagan and author's outcome. This method produces a formula that exhibits the positivity of W. Graham for the polynomials. Using this approach, we calculate the product of equivariant Schubert classes on Grassmannians, implying a stability feature of the structure factors. Although A. Knutson and T. Tao previously discovered a manifestly positive formula for such an expansion utilizing puzzle combinatorics, they did not notice the stability property. Moreover, we employ the Littlewood-Richardson polynomials to describe the multiplication law in the Casimir elements' algebra for the general linear Lie algebra, which A. Okounkov and G. Olshanski established using quantum immanents.",10,False
"Possible (algebraic) commutation relations in the Lagrangian quantum theory of free (scalar, spinor and vector) fields are considered from mathematical view-point. As sources of these relations are employed the Heisenberg equations/relations for the dynamical variables and a specific condition for uniqueness of the operators of the dynamical variables (with respect to some class of Lagrangians). The paracommutation relations or some their generalizations are pointed as the most general ones that entail the validity of all Heisenberg equations. The simultaneous fulfillment of the Heisenberg equations and the uniqueness requirement turn to be impossible. This problem is solved via a redefinition of the dynamical variables, similar to the normal ordering procedure and containing it as a special case. That implies corresponding changes in the admissible commutation relations. The introduction of the concept of the vacuum makes narrow the class of the possible commutation relations; in particular, the mentioned redefinition of the dynamical variables is reduced to normal ordering. As a last restriction on that class is imposed the requirement for existing of an effective procedure for calculating vacuum mean values. The standard bilinear commutation relations are pointed as the only known ones that satisfy all of the mentioned conditions and do not contradict to the existing data.","In the context of Lagrangian quantum theory, this study examines the potential algebraic commutation relationships between scalar, spinor, and vector fields from a mathematical perspective. To determine these relations, we utilize the Heisenberg equations and a specific uniqueness condition for the operators of the dynamic variables. We find that the paracommutation relations, or certain generalizations thereof, are the most comprehensive options that ensure the validity of all Heisenberg equations. However, we encounter an issue where satisfying both the Heisenberg equations and the uniqueness requirement simultaneously becomes impossible. To address this challenge, we introduce a redefinition of the dynamic variables, analogous to the normal ordering procedure, which includes the latter as a special case. This modification leads to adjustments in the allowable commutation relations. When considering the concept of vacuum, we restrict the range of feasible commutation relations further, ultimately arriving at the standard bilinear commutation relations as the sole known option that meets all the requirements and does not conflict with available data.",8,False
"Epitaxial self-assembled quantum dots (SAQDs) are of interest for nanostructured optoelectronic and electronic devices such as lasers, photodetectors and nanoscale logic. Spatial order and size order of SAQDs are important to the development of usable devices. It is likely that these two types of order are strongly linked; thus, a study of spatial order will also have strong implications for size order. Here a study of spatial order is undertaken using a linear analysis of a commonly used model of SAQD formation based on surface diffusion. Analytic formulas for film-height correlation functions are found that characterize quantum dot spatial order and corresponding correlation lengths that quantify order. Initial atomic-scale random fluctuations result in relatively small correlation lengths (about two dots) when the effect of a wetting potential is negligible; however, the correlation lengths diverge when SAQDs are allowed to form at a near-critical film height. The present work reinforces previous findings about anisotropy and SAQD order and presents as explicit and transparent mechanism for ordering with corresponding analytic equations. In addition, SAQD formation is by its nature a stochastic process, and various mathematical aspects regarding statistical analysis of SAQD formation and order are presented.","Epitaxial self-assembled quantum dots (SAQDs) hold great promise for use in advanced optoelectronic and electronic devices, including lasers, photodetectors, and nanoscale logic systems. To realize their full potential, it's essential to understand and control the spatial and size orders of SAQDs. This study focuses on understanding the spatial order of SAQDs, which is expected to be closely related to size order. Using a widely employed model of SAQD formation based on surface diffusion, we derived analytical formulas for film-height correlation functions that describe the spatial order of SAQDs and quantify the degree of order through correlation lengths. Our results show that initial random fluctuations lead to moderate correlation lengths (on the order of two dots) when the wetting potential has a negligible impact. However, the correlation lengths increase significantly when SAQDs are formed at a critical film height, indicating enhanced ordering. Our findings support previous research highlighting the importance of anisotropy and SAQD order. Moreover, we provide a clear and transparent mechanism for understanding ordering phenomena, accompanied by explicit analytical equations. Notably, SAQD formation is inherently a stochastic process, and our study sheds light on various statistical aspects of SAQD formation and order.",9,False
"In the article [Petojevic 2006], A. Petojevi\\' c verified useful properties of the $K_{i}(z)$ functions which generalize Kurepa's [Kurepa 1971] left factorial function. In this note, we present simplified proofs of two of these results and we answer the open question stated in [Petojevic 2006]. Finally, we discuss the differential transcendency of the $K_{i}(z)$ functions.","The paper by Petojevic (2006) established important properties of the $K_i(z)$ functions, which are extensions of Kurepa's (1971) left factorial function. This note provides streamlined proof of two of those results and resolves an open query posed in Petojevic (2006). Additionally, it explores the differential transcendence of the $K_i(z)$ functions.",10,False
"The fractional Aharonov-Bohm oscillation (FABO) of narrow quantum rings with two electrons has been studied and has been explained in an analytical way, the evolution of the period and amplitudes against the magnetic field can be exactly described. Furthermore, the dipole transition of the ground state was found to have essentially two frequencies, their difference appears as an oscillation matching the oscillation of the persistent current exactly. A number of equalities relating the observables and dynamical parameters have been found.","The behavior of narrow quantum rings containing two electrons has been thoroughly examined, specifically regarding the fractional Aharonov-Bohm oscillation (FABO). Researchers have successfully developed an analytical explanation for the phenomenon, providing insight into how the period and amplitude change in response to magnetic fields. Notably, the study revealed that the ground state's dipole transition possesses two distinct frequencies, which are synchronized with the persistent current's oscillations. Additionally, researchers discovered several interesting relationships between observable properties and dynamic parameters.",10,False
No abstract given; compares pairs of languages from World Atlas of Language Structures.,"The study does not provide an abstract summary. Instead, it focuses on comparing pairs of languages from the World Atlas of Language Structures.",10,False
"In present paper we propose seemingly new method for finding solutions of some types of nonlinear PDEs in closed form. The method is based on decomposition of nonlinear operators on sequence of operators of lower orders. It is shown that decomposition process can be done by iterative procedure(s), each step of which is reduced to solution of some auxiliary PDEs system(s) for one dependent variable. Moreover, we find on this way the explicit expression of the first-order PDE(s) for first integral of decomposable initial PDE. Remarkably that this first-order PDE is linear if initial PDE is linear in its highest derivatives. The developed method is implemented in Maple procedure, which can really solve many of different order PDEs with different number of independent variables. Examples of PDEs with calculated their general solutions demonstrate a potential of the method for automatic solving of nonlinear PDEs.","In this study, we introduce a novel approach for obtaining exact solutions to certain types of nonlinear partial differential equations (PDEs). Our method involves breaking down nonlinear operators into a series of simpler operators of lower order, which can be achieved through an iterative process. Each iteration requires the solution of a set of auxiliary PDEs involving a single dependent variable. Notably, we derive an explicit formula for the first-order PDEs corresponding to the first integral of the original decomposable PDE. Interestingly, this first-order PDE turns out to be linear when the initial PDE is linear in its highest derivatives. We have implemented our technique in a Maple procedure, which has been successfully applied to various PDEs with differing numbers of independent variables and orders. Several examples are provided to showcase the effectiveness of our method in automatically solving nonlinear PDEs.",10,False
"This paper is an exposition of the so-called injective Morita contexts (in which the connecting bimodule morphisms are injective) and Morita $\\alpha$contexts (in which the connecting bimodules enjoy some local projectivity in the sense of Zimmermann-Huisgen). Motivated by situations in which only one trace ideal is in action, or the compatibility between the bimodule morphisms is not needed, we introduce the notions of Morita semi-contexts and Morita data, and investigate them. Injective Morita data will be used (with the help of static and adstatic modules) to establish equivalences between some intersecting subcategories related to subcategories of modules that are localized or colocalized by trace ideals of a Morita datum. We end up with applications of Morita $\\alpha$-contexts to $\\ast$-modules and injective right wide Morita contexts.","This paper delves into the realm of Morita contexts, specifically focusing on two types: injective Morita contexts, where the connecting bimodule morphisms are injective, and Morita αcontexts, where the connecting bimodules possess local projectivity à la Zimmermann-Huisgen. The authors' motivation stems from scenarios where a single trace ideal is involved or the compatibility between bimodule morphisms is unnecessary. They introduce the concepts of Morita semi-contexts and Morita data, which they explore in depth. By utilizing injective Morita data, along with static and adstatic modules, the authors establish connections between various intersecting subcategories associated with subcategories of modules that are localized or co-localized by trace ideals of a Morita datum. Ultimately, the study culminates in applications of Morita αcontexts to *-modules and injective right wide Morita contexts.",8,False
"There has been important experimental progress in the sector of heavy baryons in the past several years. We study the strong decays of the S-wave, P-wave, D-wave and radially excited charmed baryons using the $^3P_0$ model. After comparing the calculated decay pattern and total width with the available data, we discuss the possible internal structure and quantum numbers of those charmed baryons observed recently.","Significant strides have been made in the field of heavy baryons in recent years, specifically regarding the study of their strong decays. Our research focuses on the S-wave, P-wave, D-wave, and radially excited charmed baryons, employing the $^3P_0$ model to examine their decay patterns and total widths. By comparing our calculations with existing data, we aim to gain insights into the internal composition and quantum numbers of these newly discovered charmed baryons.",7,False
"Precision tests of the Kobayashi-Maskawa model of CP violation are discussed, pointing out possible signatures for other sources of CP violation and for new flavor-changing operators. The current status of the most accurate tests is summarized.","The Kobayashi-Maskawa model of CP violation is thoroughly examined through precision tests, which aim to identify signs of additional sources of CP violation and novel flavor-changing operators. An overview of the current state of the most reliable tests is provided, offering insights into the existing understanding of this fundamental concept in particle physics.",8,False
"The Dark Energy problem is forcing us to re-examine our models and our understanding of relativity and space-time. Here a novel idea of Fundamental Forces is introduced. This allows us to perceive the General Theory of Relativity and Einstein's Equation from a new pesrpective. In addition to providing us with an improved understanding of space and time, it will be shown how it leads to a resolution of the Dark Energy problem.","The enigma of dark energy compels us to reassess our comprehension of relativity and spacetime, as well as our theoretical frameworks. A groundbreaking concept of Fundamental Forces is put forth in this context. By embracing this innovative perspective, we gain fresh insights into both the General Theory of Relativity and Einstein's Equation. Aside from offering a deeper understanding of space and time, it becomes evident that this approach holds the key to resolving the puzzle of dark energy.",8,False
We present a critical review about the study of linear perturbations of matched spacetimes including gauge problems. We analyse the freedom introduced in the perturbed matching by the presence of background symmetries and revisit the particular case of spherically symmetry in n-dimensions. This analysis includes settings with boundary layers such as brane world models and shell cosmologies.,"In this review, we examine the investigation of linear disturbances in synchronized spacetimes, with a focus on the challenges posed by gauge issues. Our analysis highlights the flexibility brought into the perturbed matching process by the existence of underlying symmetries in the background. Specifically, we reassess the well-known example of spherical symmetry in higher dimensions, taking into account scenarios that involve boundary layers, such as brane world models and shell cosmologies.",8,False
"We define nonselfadjoint operator algebras with generators $L_{e_1},..., L_{e_n}, L_{f_1},...,L_{f_m}$ subject to the unitary commutation relations of the form \\[ L_{e_i}L_{f_j} = \\sum_{k,l} u_{i,j,k,l} L_{f_l}L_{e_k}\\] where $u= (u_{i,j,k,l})$ is an $nm \\times nm$ unitary matrix. These algebras, which generalise the analytic Toeplitz algebras of rank 2 graphs with a single vertex, are classified up to isometric isomorphism in terms of the matrix $u$.","We consider operator algebras that lack self-adjointness and are generated by elements $L_{e_1}, \ldots, L_{e_n}, L_{f_1}, \ldots, L_{f_m}$. These generators satisfy unityary commutation relations of the form $L_{e_i}L_{f_j} = \sum_{k,l} u_{i,j,k,l} L_{f_l}L_{e_k}$, where $u$ is a unitary $nm \times nm$ matrix. These algebras extend the analytic Toeplitz algebras of rank 2 graphs with a single vertex and are classified up to isometric isomorphism using the matrix $u$.",9,False
"We show that the globular cluster mass function (GCMF) in the Milky Way depends on cluster half-mass density (rho_h) in the sense that the turnover mass M_TO increases with rho_h while the width of the GCMF decreases. We argue that this is the expected signature of the slow erosion of a mass function that initially rose towards low masses, predominantly through cluster evaporation driven by internal two-body relaxation. We find excellent agreement between the observed GCMF -- including its dependence on internal density rho_h, central concentration c, and Galactocentric distance r_gc -- and a simple model in which the relaxation-driven mass-loss rates of clusters are approximated by -dM/dt = mu_ev ~ rho_h^{1/2}. In particular, we recover the well-known insensitivity of M_TO to r_gc. This feature does not derive from a literal ``universality'' of the GCMF turnover mass, but rather from a significant variation of M_TO with rho_h -- the expected outcome of relaxation-driven cluster disruption -- plus significant scatter in rho_h as a function of r_gc. Our conclusions are the same if the evaporation rates are assumed to depend instead on the mean volume or surface densities of clusters inside their tidal radii, as mu_ev ~ rho_t^{1/2} or mu_ev ~ Sigma_t^{3/4} -- alternative prescriptions that are physically motivated but involve cluster properties (rho_t and Sigma_t) that are not as well defined or as readily observable as rho_h. In all cases, the normalization of mu_ev required to fit the GCMF implies cluster lifetimes that are within the range of standard values (although falling towards the low end of this range). Our analysis does not depend on any assumptions or information about velocity anisotropy in the globular cluster system.","The study reveals that the mass function of globular clusters in the Milky Way galaxy is influenced by the cluster's density, with more dense clusters having a higher turnover mass and a narrower mass distribution. This observation supports the theory that cluster evaporation, caused by internal two-body relaxation, shapes the mass function over time. A simple model that takes into account the rate of mass loss due to evaporation accurately predicts the observed relationship between cluster density and turnover mass. Additionally, the study shows that the insensitivity of the turnover mass to galactocentric distance can be explained by variations in cluster density and scatter in the relation between density and distance. The results hold true when using different formulations of the evaporation rate based on cluster properties, implying that the normalization of the evaporation rate consistent with the data corresponds to cluster lifetimes within the commonly accepted range, albeit leaning towards the lower end. Notably, the analysis did not rely on any specific assumptions or knowledge regarding velocity anisotropy in the globular cluster system.",5,False
We discussed quantum deformations of D=4 Lorentz and Poincare algebras. In the case of Poincare algebra it is shown that almost all classical r-matrices of S. Zakrzewski classification correspond to twisted deformations of Abelian and Jordanian types. A part of twists corresponding to the r-matrices of Zakrzewski classification are given in explicit form.,"During our conversation, we explored ways to modify the structure of spacetime by deforming the symmetries of four-dimensional space and time. Specifically, we looked at how the Poincaré algebra, which describes the symmetry properties of spacetime, can be modified or deformed"" in various ways. We found that many of these deformations, known as ""twisted deformations,"" can be classified into two main types: Abelian and Jordanian. Furthermore, we were able to explicitly express some of the twists associated with these deformations using a set of mathematical formulas.",4,False
"The path integral over Euclidean geometries for the recently suggested density matrix of the Universe is shown to describe a microcanonical ensemble in quantum cosmology. This ensemble corresponds to a uniform (weight one) distribution in phase space of true physical variables, but in terms of the observable spacetime geometry it is peaked about complex saddle-points of the {\\em Lorentzian} path integral. They are represented by the recently obtained cosmological instantons limited to a bounded range of the cosmological constant. Inflationary cosmologies generated by these instantons at late stages of expansion undergo acceleration whose low-energy scale can be attained within the concept of dynamically evolving extra dimensions. Thus, together with the bounded range of the early cosmological constant, this cosmological ensemble suggests the mechanism of constraining the landscape of string vacua and, simultaneously, a possible solution to the dark energy problem in the form of the quasi-equilibrium decay of the microcanonical state of the Universe.","The universe's density matrix, which was proposed recently, has been found to represent a microcanonical ensemble when integrated over Euclidean geometries. This ensemble is characterized by a uniform distribution in phase space of genuine physical variables, but it peaks around intricate saddle-points of the Lorentzian path integral that correspond to observational spacetime geometry. These saddle-points are represented by cosmological instantons that have been discovered recently and are confined to a finite range of the cosmological constant. Accelerating inflationary cosmologies arise from these instantons during the later stages of expansion, and they can achieve a low-energy scale through the notion of dynamically changing extra dimensions. Along with the restricted range of the early cosmological constant, this cosmological ensemble offers a potential answer to the dark energy issue in the guise of the quasi-equilibrium degradation of the microcanonical condition of the cosmos and a means of restricting the landscape of string vacua.",9,False
"We discuss a universality property of any covariant field theory in space-time expanded around pp-wave backgrounds. According to this property the space-time lagrangian density evaluated on a restricted set of field configurations, called universal sector, turns out to be same around all the pp-waves, even off-shell, with same transverse space and same profiles for the background scalars. In this paper we restrict our discussion to tensorial fields only. In the context of bosonic string theory we consider on-shell pp-waves and argue that universality requires the existence of a universal sector of world-sheet operators whose correlation functions are insensitive to the pp-wave nature of the metric and the background gauge flux. Such results can also be reproduced using the world-sheet conformal field theory. We also study such pp-waves in non-polynomial closed string field theory (CSFT). In particular, we argue that for an off-shell pp-wave ansatz with flat transverse space and dilaton independent of transverse coordinates the field redefinition relating the low energy effective field theory and CSFT with all the massive modes integrated out is at most quadratic in fields. Because of this simplification it is expected that the off-shell pp-waves can be identified on the two sides. Furthermore, given the massless pp-wave field configurations, an iterative method for computing the higher massive modes using the CSFT equations of motion has been discussed. All our bosonic string theory analyses can be generalised to the common Neveu-Schwarz sector of superstrings.","The article examines a fundamental characteristic of any generally covariant field theory in spacetime, focusing on its behavior in the presence of plane wave backgrounds. Specifically, the authors show that certain field configurations, referred to as the universal sector,"" have the remarkable property of being identical across all plane waves, regardless of their profile or the specific solution used. This holds true even when considering off-shell configurations, where the field theory is not necessarily describing physical states. Restricting their attention to tensor fields, the authors explore the implications of this universality property in various contexts. Within the framework of bosonic string theory, they demonstrate that it leads to the existence of a set of world-sheet operators whose correlators remain unchanged under changes in the plane wave's nature or background gauge field. By employing world-sheet conformal field theory, similar conclusions can be reached. Moreover, the authors investigate non-polynomial closed string field theory (CSFT) and reveal that, under certain conditions, the field redefinition connecting the low-energy effective field theory and CSFT with all massive modes integrated out is at most quadratic in the fields. This greatly facilitates identifying the off-shell plane wave solutions on both sides. Additionally, the authors outline an iterative approach for calculating higher massive modes by utilizing the CSFT equations of motion, starting from massless plane wave field configurations. It is worth mentioning that all the findings in the realm of bosonic string theory can be extended to the shared Neveu-Schwarz sector of superstrings.",9,False
"We give a quantitative analysis of clustering in a stochastic model of one-dimensional gas. At time zero, the gas consists of $n$ identical particles that are randomly distributed on the real line and have zero initial speeds. Particles begin to move under the forces of mutual attraction. When particles collide, they stick together forming a new particle, called cluster, whose mass and speed are defined by the laws of conservation. We are interested in the asymptotic behavior of $K_n(t)$ as $n\\to \\infty$, where $K_n(t)$ denotes the number of clusters at time $t$ in the system with $n$ initial particles. Our main result is a functional limit theorem for $K_n(t)$. Its proof is based on the discovered localization property of the aggregation process, which states that the behavior of each particle is essentially defined by the motion of neighbor particles.","In this study, we examine the clustering phenomenon in a probabilistic model of a one-dimensional gas. The system starts with $n$ indistinguishable particles positioned randomly along the real line, all having zero initial velocity. As time progresses, the particles move due to their mutual attraction, causing them to collide and merge into larger clusters. By conserving mass and momentum, the newly formed clusters acquire well-defined properties. Our focus lies in investigating the long-term behavior of $K_n(t)$, the quantity of clusters present at time $t$ when starting with $n$ initial particles. Our primary finding is a functional limit theorem for $K_n(t)$, which relies on the observed localization property of the aggregation process. This property reveals that the movement of nearby particles primarily determines each particle's behavior, enabling us to better understand the clustering dynamics.",8,False
"Our main result in this paper is the following: Given $H^m, H^n$ hyperbolic spaces of dimensional $m$ and $n$ corresponding, and given a Holder function $f=(s^1,...,f^{n-1}):\\partial H^m\\to \\partial H^n$ between geometric boundaries of $H^m$ and $H^n$. Then for each $\\epsilon >0$ there exists a harmonic map $u:H^m\\to H^n$ which is continuous up to the boundary (in the sense of Euclidean) and $u|_{\\partial H^m}=(f^1,...,f^{n-1},\\epsilon)$.","In this paper, we present a significant finding: given two hyperbolic spaces $H^m$ and $H^n$ with dimensions $m$ and $n$, respectively, and a Holder function $f$ that maps the boundary of $H^m$ to the boundary of $H^n$, there exists a harmonic map $u$ that connects these two spaces. Notably, $u$ is continuous up to the boundary, meaning it can be extended continuously to the boundary of $H^m$ in the Euclidean sense, and its restriction to the boundary matches the given function $f$. Moreover, we can ensure that the map $u$ satisfies this property for any positive value of $\epsilon$.",4,False
"Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. The proposed method is demonstrated by the modeling of a return map of noisy chaotic data. In this example, the nonparametric regression is used to predict a future value of chaotic time series from the present one. The mean predictor error is used in the definition of predictor quality, while the redundancy is expressed by the mean square distance between data points. Both statistics are used in a new definition of predictor cost function. From the minimum of the predictor cost function, a proper number of data in the model is estimated.","Statistical modeling of physical laws relies on the probability distribution of observed variables, which is represented using a kernel estimator that's informed by the spread of data during experimental setup calibration. This kernel estimator is then employed to derive an optimal estimate of the physical law connecting the measured variables through a conditional average estimator, a technique analogous to non-parametric regression. The approach is showcased by modeling a return map of noisy chaotic data, where the non-parametric regression forecasts future values in the time series from current ones. Predictive performance is evaluated with two metrics: mean predictor error for assessing prediction accuracy and mean squared distance between data points to quantify redundancy. These quantities feed into a novel predictor cost function, whose minimization yields an appropriate number of data points required for the model.",8,False
Real Options for Project Schedules (ROPS) has three recursive sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA) optimization shell optimizes parameters of strategic Plans containing multiple Projects containing ordered Tasks. A middle shell samples probability distributions of durations of Tasks. An inner shell samples probability distributions of costs of Tasks. PATHTREE is used to develop options on schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to develop a relative risk analysis among projects.,"Real Options for Project Schedules (ROPS) employs a hierarchical approach with three nested shells to optimize project planning and management. The top-level shell utilizes Adaptive Simulated Annealing (ASA) optimization to determine the best set of parameters for strategic plans that contain multiple projects, each consisting of sequential tasks. The middle shell focuses on estimating the probability distribution of task duration, while the innermost shell concentrates on probabilistic cost estimation. To create flexible schedule options, PATHTREE is employed. Additionally, TRADING IN RISK DIMENSIONS (TRD) algorithms are leveraged to evaluate and compare the relative risks associated with different projects.",9,False
"We combine classical methods of combinatorial group theory with the theory of small cancellations over relatively hyperbolic groups to construct finitely generated torsion-free groups that have only finitely many classes of conjugate elements. Moreover, we present several results concerning embeddings into such groups. As another application of these techniques, we prove that every countable group $C$ can be realized as a group of outer automorphisms of a group $N$, where $N$ is a finitely generated group having Kazhdan's property (T) and containing exactly two conjugacy classes.","We utilize a fusion of traditional combinatorial group theory and the concept of small cancellations in relatively hyperbolic groups to create finitely generated torsion-free groups with a finite number of conjugacy classes. Additionally, we provide various findings related to embedding such groups. Furthermore, we demonstrate that any countable group $C$ can be represented as a group of outer automorphisms of a group $N$, where $N$ is a finitely generated group possessing Kazhdan's property (T) and consisting of precisely two conjugacy classes.",9,False
We study a recently proposed formulation of overlap fermions at finite density. In particular we compute the energy density as a function of the chemical potential and the temperature. It is shown that overlap fermions with chemical potential reproduce the correct continuum behavior.,"We investigate a newly suggested approach to understanding the behavior of overlap fermions in systems with non-zero density. Our focus is on calculating the energy density's dependence on both chemical potential and temperature. Notably, our findings indicate that overlap fermions exhibit behavior consistent with theoretical predictions when subjected to a chemical potential.",6,False
"Lattice contribution to the electronic self-energy in complex correlated oxides is a fascinating subject that has lately stimulated lively discussions. Expectations of electron-phonon self-energy effects for simpler materials, such as Pd and Al, have resulted in several misconceptions in strongly correlated oxides. Here we analyze a number of arguments claiming that phonons cannot be the origin of certain self-energy effects seen in high-$T_c$ cuprate superconductors via angle resolved photoemission experiments (ARPES), including the temperature dependence, doping dependence of the renormalization effects, the inter-band scattering in the bilayer systems, and impurity substitution. We show that in light of experimental evidences and detailed simulations, these arguments are not well founded.","The topic of lattice contributions to electronic self-energy in complex correlated oxides has recently sparked significant interest and debate. However, some misunderstandings have arisen due to assumptions made about electron-phonon self-energy effects in simpler materials like Pd and Al. In this analysis, we examine various claims that phonons cannot account for certain self-energy effects observed in high-temperature cuprate superconductors through angle-resolved photoemission experiments (ARPES). Specifically, we address the temperature dependence, doping dependence of renormalization effects, inter-band scattering in bilayer systems, and impurity substitution. Our examination reveals that these arguments are unfounded when considering experimental evidence and thorough simulations.",5,False
"We get asymptotics for the volume of large balls in an arbitrary locally compact group G with polynomial growth. This is done via a study of the geometry of G and a generalization of P. Pansu's thesis. In particular, we show that any such G is weakly commensurable to some simply connected solvable Lie group S, the Lie shadow of G. We also show that large balls in G have an asymptotic shape, i.e. after a suitable renormalization, they converge to a limiting compact set which can be interpreted geometrically. We then discuss the speed of convergence, treat some examples and give an application to ergodic theory. We also answer a question of Burago about left invariant metrics and recover some results of Stoll on the irrationality of growth series of nilpotent groups.","In this paper, we investigate the volume of large balls in a locally compact group G with polynomial growth, using techniques from geometric analysis and a generalization of Pansu's thesis. Our main result shows that any such group G is weakly commensurable to a simply connected solvable Lie group S, which we refer to as the Lie shadow of G. Additionally, we demonstrate that large balls in G have a well-defined asymptotic shape, meaning that after appropriate normalization, they converge to a compact set with a clear geometric interpretation. We further analyze the rate at which these shapes converge and provide examples to illustrate our findings. Finally, we address a question posed by Burago regarding left-invariant metrics and retrieve previously established results on the irrationality of growth series of nilpotent groups.",7,False
"In this note we present three representations of a 248-dimensional Lie algebra, namely the algebra of Lie point symmetries admitted by a system of five trivial ordinary differential equations each of order forty-four, that admitted by a system of seven trivial ordinary differential equations each of order twenty-eight and that admitted by one trivial ordinary differential equation of order two hundred and forty-four.","In this paper, we explore three different ways to represent a 248-dimensional Lie algebra, which is the symmetry algebra of a system of differential equations. The first representation is derived from a system of five trivial ODEs of order 44, the second from a system of seven trivial ODEs of order 28, and the third from a single trivial ODE of order 244.",8,False
We review recent progress in operator algebraic approach to conformal quantum field theory. Our emphasis is on use of representation theory in classification theory. This is based on a series of joint works with R. Longo.,"Recent advancements in the operator algebraic approach to conformal quantum field theory have been shaped by our collaboration with R. Longo, focusing on the application of representation theory in classification theories. We examine these developments and highlight their significance in understanding the interplay between mathematical frameworks and physical phenomena.",9,False
"Sparse Code Division Multiple Access (CDMA), a variation on the standard CDMA method in which the spreading (signature) matrix contains only a relatively small number of non-zero elements, is presented and analysed using methods of statistical physics. The analysis provides results on the performance of maximum likelihood decoding for sparse spreading codes in the large system limit. We present results for both cases of regular and irregular spreading matrices for the binary additive white Gaussian noise channel (BIAWGN) with a comparison to the canonical (dense) random spreading code.","Sparse Code Division Multiple Access (CDMA) is a variant of traditional CDMA that utilizes a spreading matrix with a limited number of non-zero elements. This approach was analyzed using statistical physics methods, providing insights into the performance of maximum likelihood decoding for sparse spreading codes in large systems. The study compared the performance of regular and irregular spreading matrices in the binary additive white Gaussian noise channel (BIWAGN) and contrasted it with the conventional (dense) random spreading code.",10,False
"For positive semidefinite matrices $A$ and $B$, Ando and Zhan proved the inequalities $||| f(A)+f(B) ||| \\ge ||| f(A+B) |||$ and $||| g(A)+g(B) ||| \\le ||| g(A+B) |||$, for any unitarily invariant norm, and for any non-negative operator monotone $f$ on $[0,\\infty)$ with inverse function $g$. These inequalities have very recently been generalised to non-negative concave functions $f$ and non-negative convex functions $g$, by Bourin and Uchiyama, and Kosem, respectively. In this paper we consider the related question whether the inequalities $||| f(A)-f(B) ||| \\le ||| f(|A-B|) |||$, and $||| g(A)-g(B) ||| \\ge ||| g(|A-B|) |||$, obtained by Ando, for operator monotone $f$ with inverse $g$, also have a similar generalisation to non-negative concave $f$ and convex $g$. We answer exactly this question, in the negative for general matrices, and affirmatively in the special case when $A\\ge ||B||$. In the course of this work, we introduce the novel notion of $Y$-dominated majorisation between the spectra of two Hermitian matrices, where $Y$ is itself a Hermitian matrix, and prove a certain property of this relation that allows to strengthen the results of Bourin-Uchiyama and Kosem, mentioned above.","The paper discusses the extension of inequalities for positive semi-definite matrices to non-negative concave and convex functions. Ando and Zhan previously proved that for any unitarily invariant norm, the inequality $||| f(A)+f(B) ||| \geq ||| f(A+B) |||$ holds for non-negative operator monotone $f$ on $[0,\infty)$ with inverse function $g$. Recently, Bourin and Uchiyama, and Kosem generalized these inequalities to non-negative concave and convex functions. The authors investigate if similar inequalities hold for non-negative concave and convex functions. They show that the answer is no for general matrices but yes for the special case when $A\geq ||B||$. Additionally, they introduce the concept of $Y$-dominated majorization between the spectra of two Hermitian matrices, which allows them to strengthen previous results by Bourin-Uchiyama and Kosem.",6,False
"The topological structure of the event horizon has been investigated in terms of the Morse theory. The elementary process of topological evolution can be understood as a handle attachment. It has been found that there are certain constraints on the nature of black hole topological evolution: (i) There are n kinds of handle attachments in (n+1)-dimensional black hole space-times. (ii) Handles are further classified as either of black or white type, and only black handles appear in real black hole space-times. (iii) The spatial section of an exterior of the black hole region is always connected. As a corollary, it is shown that the formation of a black hole with an S**(n-2) x S**1 horizon from that with an S**(n-1) horizon must be non-axisymmetric in asymptotically flat space-times.","The topological properties of black holes have been studied using Morse theory, which provides a framework for understanding the evolution of their topological structures. In this context, the creation of a black hole can be thought of as the attachment of handles"" to a space-time. These handles come in two types - black and white - and it turns out that only black handles are present in actual black hole space-times. Additionally, the spatial sections of the exterior of a black hole's event horizon are always connected. This leads to the conclusion that the formation of a black hole with an Sn-2 x S1 horizon from one with an Sn-1 horizon must be asymmetrical in space-times that are flat at infinity.",3,False
In this contribution we go through the developments that in the years 1968 to 1974 led from the Veneziano model to the bosonic string.,"During the period spanning 1968 to 1974, a series of advancements paved the way for the evolution of the Veneziano model into the bosonic string. This article delves into those key developments.",7,False
We prove a duality theorem for certain graded algebras and show by various examples different kinds of failure of tameness of local cohomology.,We demonstrate a dualism theorem for specific graded algebras and illustrate through diverse examples how the local cohomology's tameness can break down in various ways.,7,False
"The physical consistency of the match of piecewise-$C^0$ metrics is discussed. The mathematical theory of gravitational discontinuity hypersurfaces is generalized to cover the match of regularly discontinuous metrics. The mean-value differential geometry framework on a hypersurface is introduced, and corresponding compatibility conditions are deduced. Examples of generalized boundary layers, gravitational shock waves and thin shells are studied.","The article examines the concept of physically consistent matching of piecewise-$C^0$ metrics, which refers to the smooth transition between different regions of spacetime with distinct geometric properties. The authors generalize the existing mathematical theories of gravitational discontinuity hypersurfaces to accommodate this type of metric mismatch. They introduce a new framework based on mean-value differential geometry, which allows them to derive compatibility conditions for the matched metrics. The authors then explore various examples of phenomena that can be described using this approach, including generalized boundary layers, gravitational shock waves, and thin shells.",6,False
"Given an orientable weakly self-dual manifold X of rank two, we build a geometric realization of the Lie algebra sl(6,C) as a naturally defined algebra L of endomorphisms of the space of differential forms of X. We provide an explicit description of Serre generators in terms of natural generators of L. This construction gives a bundle on X which is related to the search for a natural Gauge theory on X. We consider this paper as a first step in the study of a rich and interesting algebraic structure.","In this paper, we explore the construction of a geometric realization of the special linear algebra sl(6,C) on an orientable weakly self-dual manifold X of rank two. Specifically, we define a naturally occurring algebra L of endomorphisms of the space of differential forms on X, which can be identified with sl(6,C). Furthermore, we provide a detailed description of Serre generators in terms of the natural generators of L. This work lays the foundation for a potential gauge theory on X and represents an initial step in examining the intricate algebraic structure that underlies this problem.",7,False
"We show that there is an hierarchy of intersection rigidity properties of sets in a closed symplectic manifold: some sets cannot be displaced by symplectomorphisms from more sets than the others. We also find new examples of rigidity of intersections involving, in particular, specific fibers of moment maps of Hamiltonian torus actions, monotone Lagrangian submanifolds (following the works of P.Albers and P.Biran-O.Cornea), as well as certain, possibly singular, sets defined in terms of Poisson-commutative subalgebras of smooth functions. In addition, we get some geometric obstructions to semi-simplicity of the quantum homology of symplectic manifolds. The proofs are based on the Floer-theoretical machinery of partial symplectic quasi-states.","In this study, we demonstrate that there exists a hierarchical structure among the intersection rigidity properties of sets within a closed symplectic manifold. Specifically, we discover that certain sets are less susceptible to displacement via symplectomorphisms compared to others. Our research uncovers novel instances of intersection rigidity, including those involving specific fibers of moment maps associated with Hamiltonian torus actions, monotone Lagrangian submanifolds (as explored by P. Albers and P. Biran-O. Cornea), and distinctive, potentially singular, sets defined through Poisson-commutative subalgebras of smooth functions. Moreover, our work reveals geometric obstacles to the semi-simplicity of the quantum homology of symplectic manifolds. The foundation of our arguments relies on the Floer-theoretic framework of partial symplectic quasi-states.",10,False